{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kareemrb27/Lab2.1/blob/master/CV_1_Assignment_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CIFAR-10 Image Classification Using CNN Architectures\n",
        "\n",
        "\n",
        "#### **Objective:**  \n",
        "Develop and compare deep learning models for **image classification** on the **CIFAR-10 dataset** using different **Convolutional Neural Network (CNN) architectures**. The goal is to train models that can accurately classify images into **10 object categories** and analyze their performance.\n",
        "\n",
        "#### **Scope:**  \n",
        "1. **Data Processing & Augmentation:**  \n",
        "   - Load the **CIFAR-10 dataset** and apply **data augmentation techniques** (random cropping, flipping, and normalization) to improve generalization.  \n",
        "   - Utilize **DataLoaders** for efficient training and evaluation.\n",
        "\n",
        "2. **Model Development:**  \n",
        "   - Implement **three CNN architectures**:  \n",
        "     - **VGG16**: A deep CNN with multiple convolutional layers.  \n",
        "     - **VGG19**: An extended version of VGG16 with additional layers.  \n",
        "     - **ResNet-50**: A deep residual network with skip connections to improve gradient flow.  \n",
        "   - Develop a **Hybrid Model** that combines **VGG16, VGG19, and ResNet-50** to leverage the strengths of all three architectures.\n",
        "\n",
        "3. **Training & Optimization:**  \n",
        "   - Train models using **cross-entropy loss and stochastic gradient descent (SGD)** with momentum.  \n",
        "   - Implement **learning rate scheduling** (Cosine Annealing) to optimize convergence.  \n",
        "   - Validate models on the **test dataset** to measure generalization performance.\n",
        "\n",
        "4. **Evaluation & Performance Analysis:**  \n",
        "   - Compute **classification metrics**: **Accuracy, Precision, Recall, F1-score**, and **Confusion Matrix**.  \n",
        "   - Compare the **performance of all four models** and determine which model performs best on the CIFAR-10 dataset.\n",
        "\n",
        "5. **Visualization & Interpretability:**  \n",
        "   - Display **model predictions** on test images.  \n",
        "   - Extract and **visualize convolutional feature maps** to analyze how the models learn image representations.\n",
        "\n",
        "#### **Expected Outcome:**  \n",
        "- A **trained and evaluated deep learning model** capable of classifying images from CIFAR-10 with high accuracy.  \n",
        "- **Comparison of different architectures** to determine the most effective model for image classification.  \n",
        "- **Insights into model behavior** through feature visualization and performance metrics.  \n"
      ],
      "metadata": {
        "id": "iNFWJ3r8U0Nm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wldIuF0cj_Z7"
      },
      "source": [
        "## Mounting the asset directory containing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_KdNO_NAGaB",
        "outputId": "93f2bb46-8265-4e4f-d3f8-351046e5b2fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "local_assets_b = False\n",
        "\n",
        "if local_assets_b:\n",
        "  assets_dir = \"/content/assets/Assignment/\"\n",
        "\n",
        "  if not os.path.isdir(assets_dir):\n",
        "    assert os.path.isfile(\"assets.zip\")\n",
        "    os.system(\"unzip assets.zip\")\n",
        "else:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  assets_dir = '/content/drive/MyDrive/IK/CV1/assets/Assignment/' #Use the path of the assets in your drive here"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation"
      ],
      "metadata": {
        "id": "NQ1jyTsjsCfd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyBnqEZ09zRr"
      },
      "source": [
        "#### What dataset are we using?\n",
        "We will be working on CIFAR-10 which is a widely used benchmark dataset in computer vision and machine learning. It consists of 60,000 small-sized color images (32x32 pixels) belonging to 10 different classes, with 6,000 images per class. The dataset is split into a training set of 50,000 images and a test set of 10,000 images. The classes in CIFAR-10 include common objects like airplanes, automobiles, birds, cats, deer, dogs, frogs, horses, ships, and trucks. CIFAR-10 serves as a good dataset for evaluating and benchmarking image classification models.\n",
        "\n",
        "When it comes to transfer learning, VGG is often used as a backbone model. Its pre-trained weights, which have been learned on the large-scale ImageNet dataset, capture generic features like edges, textures, and shapes that are beneficial for various visual recognition tasks. By leveraging the pre-trained VGG model, we can fine-tune it on the CIFAR-10 dataset to perform image classification. The lower-level layers of VGG capture low-level features, such as edges and corners, while the higher-level layers learn more complex features. This enables VGG to extract meaningful representations from images and generalize well to new tasks with limited labeled data.\n",
        "\n",
        "By fine-tuning VGG on the CIFAR-10 dataset, we can take advantage of the pre-trained weights and learn task-specific features for image classification. This approach is effective when the target task has a similar domain or visual characteristics as the source task on which VGG was pre-trained. Transfer learning with VGG can help achieve better performance on CIFAR-10 by leveraging the knowledge learned from ImageNet, even with a smaller dataset.\n",
        "\n",
        "\n",
        "These are the classes present in CIFAR-10:\n",
        "\n",
        " `('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wrl9JLI79zRs"
      },
      "source": [
        "### Image Transformation\n",
        "We will be performing the following transformations for training:\n",
        "\n",
        "*   Random Crop\n",
        "*   Flip\n",
        "*   Normalize data\n",
        "\n",
        "Test time Transformations:\n",
        "\n",
        "* Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLmf8ZaFeuMS"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import torch  # PyTorch library for tensor computations and deep learning\n",
        "import torchvision  # PyTorch library for handling image datasets and models\n",
        "import torchvision.transforms as transforms  # Transformations for image preprocessing\n",
        "\n",
        "import torch.nn as nn  # Neural network modules\n",
        "import torch.optim as optim  # Optimizers for training the model\n",
        "import torch.nn.functional as F  # Functional API for activation functions and loss functions\n",
        "\n",
        "import numpy as np  # Numerical operations\n",
        "import matplotlib.pyplot as plt  # Visualization\n",
        "\n",
        "# Define transformations for the training dataset (includes data augmentation)\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),  # Randomly crops a 32x32 region with 4 pixels padding (helps with spatial invariance)\n",
        "    transforms.RandomHorizontalFlip(),  # Randomly flips the image horizontally (improves generalization)\n",
        "    transforms.ToTensor(),  # Converts image to PyTorch tensor and normalizes pixel values to [0,1]\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2434, 0.2616))\n",
        "    # Normalizes the image using mean and standard deviation of the CIFAR-10 dataset\n",
        "])\n",
        "\n",
        "# Define transformations for the test dataset (only normalization, no augmentation)\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Converts image to PyTorch tensor\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2434, 0.2616))\n",
        "    # Normalizes test images (same mean and standard deviation as training set)\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6eo6IYX9zRt"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "Datasets are the collections of your training, validation, and test data. They consist of input samples and their corresponding target labels (for supervised learning). In PyTorch, datasets are typically created using custom classes inheriting from `torch.utils.data.Dataset`. You load your data into this class, allowing easy access during training. PyTorch provides built-in datasets like MNIST, CIFAR-10, and ImageNet, but custom datasets can also be created to work with specific data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Preparing dataset\n",
        "\n",
        "# Load the CIFAR-10 training dataset with transformations\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',  # Directory where the dataset will be stored/downloaded\n",
        "    train=True,  # Load the training dataset (if False, loads the test set)\n",
        "    download=True,  # Download the dataset if not already present\n",
        "    transform=transform_train  # Apply defined transformations (augmentation + normalization)\n",
        ")\n",
        "\n",
        "# Load the CIFAR-10 test dataset with transformations\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data',  # Directory where the dataset will be stored/downloaded\n",
        "    train=False,  # Load the test dataset (train=False)\n",
        "    download=True,  # Download the dataset if not already present\n",
        "    transform=transform_test  # Apply defined transformations (only normalization)\n",
        ")\n"
      ],
      "metadata": {
        "id": "1SBooIIs0Ih2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f2abb0a-85bf-4853-e3db-74cd2f340626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybP2HJdbMvQ_"
      },
      "source": [
        "### Dataloaders\n",
        "\n",
        "Dataloaders, are utilities that enable efficient data loading and batching. They take a dataset as input and allow users to define batch sizes, shuffle the data, and apply transformations to the samples. Dataloaders are especially useful when dealing with large datasets, as they enable the model to process data in small batches, reducing memory requirements and speeding up training. They are key components in PyTorch that facilitate data handling and preparation for machine learning tasks."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a DataLoader for the test dataset\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset,  # Test dataset\n",
        "    batch_size=256,  # Number of images per batch (larger batch size speeds up evaluation)\n",
        "    shuffle=True,  # Shuffle test data for randomized batch order\n",
        "    num_workers=2  # Number of CPU threads for parallel data loading (improves efficiency)\n",
        ")\n",
        "\n",
        "# Create a DataLoader for the training dataset\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset,  # Training dataset\n",
        "    batch_size=128,  # Number of images per batch (128 images are processed at a time)\n",
        "    shuffle=True,  # Shuffle training data at every epoch to improve generalization\n",
        "    num_workers=2  # Number of CPU threads for parallel data loading\n",
        ")\n"
      ],
      "metadata": {
        "id": "IDXvcndJ0R-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define class names corresponding to the CIFAR-10 dataset labels\n",
        "classes = ('airplane', 'bird', 'car', 'cat', 'deer', 'dog', 'horse', 'monkey', 'ship', 'truck')\n",
        "\n",
        "# Fetch a batch of training images and labels\n",
        "images, target = next(iter(trainloader))\n",
        "# `images` is a batch of image tensors with shape (batch_size, channels, height, width)\n",
        "# `target` contains the corresponding labels for the images\n",
        "\n",
        "# Convert the PyTorch tensor to a NumPy array for analysis\n",
        "np_images = images.numpy()\n",
        "\n",
        "# Print the shapes of the images and target tensors\n",
        "print(np.shape(np_images))  # Expected shape: (batch_size, 3, 32, 32) → (128, 3, 32, 32)\n",
        "print(np.shape(target))  # Expected shape: (batch_size,) → (128,)\n",
        "\n",
        "# Calculate the mean and standard deviation of the first image in the batch\n",
        "mean = np.mean(np_images[:1], axis=(0, 2, 3))  # Compute mean across channels (RGB)\n",
        "std = np.std(np_images[:1], axis=(0, 2, 3))  # Compute standard deviation across channels (RGB)\n",
        "\n",
        "# Print the calculated mean and standard deviation\n",
        "print(\"mean: \", mean)  # Displays the per-channel mean values\n",
        "print(\"std: \", std)  # Displays the per-channel standard deviation values\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJvBLtUetBPH",
        "outputId": "755d759c-1814-4f09-c18f-4649c0019422"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 3, 32, 32)\n",
            "torch.Size([128])\n",
            "mean:  [0.19538437 0.06863078 0.12578025]\n",
            "std:  [1.1375759 1.0962102 1.0899098]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIhI7qGCIIxx"
      },
      "source": [
        "## VGG\n",
        "\n",
        "\n",
        "### What is VGG?\n",
        "VGG (Visual Geometry Group) is a popular deep convolutional neural network (CNN) architecture developed by the Visual Geometry Group at the University of Oxford. VGGNet is known for its simplicity and effectiveness in image classification tasks. It consists of multiple convolutional layers followed by fully connected layers. The most common variant, VGG-16, has 16 layers, including 13 convolutional layers and 3 fully connected layers. VGGNet has achieved impressive results on various image classification benchmarks, including the ImageNet challenge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6HPHebnRzEG"
      },
      "outputs": [],
      "source": [
        "# Import required modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5Pdyz3fQDLR"
      },
      "source": [
        "### VGG16\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2CkXLRQQH5m"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class VGG16(nn.Module):\n",
        "    def __init__(self, num_classes=10):  # Assuming CIFAR-10 (10 classes)\n",
        "        super(VGG16, self).__init__()\n",
        "\n",
        "        # Feature extraction layers (Convolutional + ReLU + MaxPooling)\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1: First two convolutional layers + ReLU activation\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Downsampling (32x32 -> 16x16)\n",
        "\n",
        "            # Block 2: Two convolutional layers + ReLU + MaxPooling\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Downsampling (16x16 -> 8x8)\n",
        "\n",
        "            # Block 3: Three convolutional layers + ReLU\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "\n",
        "            # Block 4: Three convolutional layers + ReLU\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "\n",
        "            # Block 5: Three convolutional layers + ReLU + MaxPooling\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)  # Final downsampling (8x8 -> 4x4)\n",
        "        )\n",
        "\n",
        "        # Fully connected layers (Classifier)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(512 * 4 * 4, 4096), nn.ReLU(True), nn.Dropout(),  # First FC layer\n",
        "            nn.Linear(4096, 4096), nn.ReLU(True), nn.Dropout(),  # Second FC layer\n",
        "            nn.Linear(4096, num_classes)  # Output layer (10 classes for CIFAR-10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the VGG16 model.\n",
        "\n",
        "        Args:\n",
        "        - x (Tensor): Input image batch of shape (batch_size, 3, 32, 32) for CIFAR-10\n",
        "\n",
        "        Returns:\n",
        "        - Tensor: Output logits of shape (batch_size, num_classes)\n",
        "        \"\"\"\n",
        "        x = self.features(x)  # Pass input through convolutional layers\n",
        "        x = x.view(x.size(0), -1)  # Flatten feature maps into a 1D vector\n",
        "        x = self.classifier(x)  # Pass through fully connected layers\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train VGG16"
      ],
      "metadata": {
        "id": "w-3auGu_sS9G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QLElCxx87l-"
      },
      "outputs": [],
      "source": [
        "# Instantiate the VGG16 model with 10 output classes (for CIFAR-10)\n",
        "vgg16_model = VGG16(num_classes=10)\n",
        "\n",
        "# Select device: Use GPU if available, otherwise default to CPU\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Move the model to the selected device (GPU or CPU)\n",
        "vgg16_model = vgg16_model.to(device)\n",
        "\n",
        "# Define learning rate\n",
        "lr = 0.001  # Initial learning rate for training\n",
        "\n",
        "# Define the loss function (CrossEntropyLoss for multi-class classification)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer (Stochastic Gradient Descent with momentum and weight decay)\n",
        "vgg_optimizer = optim.SGD(\n",
        "    vgg16_model.parameters(),  # Model parameters to optimize\n",
        "    lr=lr,  # Learning rate (step size for updates)\n",
        "    momentum=0.9,  # Momentum helps accelerate gradient updates\n",
        "    weight_decay=5e-4  # L2 regularization (prevents overfitting by penalizing large weights)\n",
        ")\n",
        "\n",
        "# Define a learning rate scheduler (Cosine Annealing Learning Rate Decay)\n",
        "vgg_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    vgg_optimizer,  # Optimizer to adjust learning rate\n",
        "    T_max=200  # Number of epochs before completing one cosine cycle\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TuZDyJwgqT3"
      },
      "outputs": [],
      "source": [
        "def train_batch(epoch, model, optimizer):\n",
        "    \"\"\"\n",
        "    Trains the model for one epoch using the training dataset.\n",
        "\n",
        "    Args:\n",
        "    - epoch (int): The current training epoch number.\n",
        "    - model (nn.Module): The VGG16 model to be trained.\n",
        "    - optimizer (torch.optim): The optimizer used for updating model weights.\n",
        "\n",
        "    Prints:\n",
        "    - Training loss and accuracy for the current epoch.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Epoch\", epoch)  # Print the current epoch number\n",
        "    model.train()  # Set the model to training mode (enables dropout, batch norm updates)\n",
        "\n",
        "    train_loss = 0  # Variable to accumulate total loss\n",
        "    correct = 0  # Counter for correctly classified samples\n",
        "    total = 0  # Counter for total samples processed\n",
        "\n",
        "    # Iterate over the training batches\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "\n",
        "        # Move input data and targets to the same device as the model (CPU/GPU)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Clear previous gradients\n",
        "        outputs = model(inputs)  # Forward pass: Get model predictions\n",
        "\n",
        "        loss = criterion(outputs, targets)  # Compute loss using CrossEntropyLoss\n",
        "        loss.backward()  # Backpropagation: Compute gradients\n",
        "        optimizer.step()  # Update model parameters\n",
        "\n",
        "        train_loss += loss.item()  # Accumulate total loss\n",
        "\n",
        "        _, predicted = outputs.max(1)  # Get predicted class index (argmax over class dimension)\n",
        "        total += targets.size(0)  # Count total samples processed\n",
        "        correct += predicted.eq(targets).sum().item()  # Count correct predictions\n",
        "\n",
        "    # Print training statistics: Batch index, total loss, and accuracy\n",
        "    print(batch_idx, len(trainloader),\n",
        "          'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "          % (train_loss / (batch_idx + 1),  # Average loss per batch\n",
        "             100. * correct / total,  # Compute accuracy percentage\n",
        "             correct, total))  # Display correct/total samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XlW0ZsAguKC"
      },
      "outputs": [],
      "source": [
        "def validate_batch(epoch, model):\n",
        "    \"\"\"\n",
        "    Evaluates the model on the test dataset for one epoch.\n",
        "\n",
        "    Args:\n",
        "    - epoch (int): The current epoch number.\n",
        "    - model (nn.Module): The trained model to be evaluated.\n",
        "\n",
        "    Prints:\n",
        "    - Validation loss and accuracy for the current epoch.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode (disables dropout, batch norm updates)\n",
        "\n",
        "    test_loss = 0  # Variable to accumulate total validation loss\n",
        "    correct = 0  # Counter for correctly classified samples\n",
        "    total = 0  # Counter for total samples processed\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation (reduces memory usage, speeds up validation)\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            # Move inputs and targets to the same device as the model (CPU/GPU)\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)  # Forward pass: Get model predictions\n",
        "            loss = criterion(outputs, targets)  # Compute loss using CrossEntropyLoss\n",
        "\n",
        "            test_loss += loss.item()  # Accumulate total loss\n",
        "            _, predicted = outputs.max(1)  # Get predicted class (argmax over class dimension)\n",
        "            total += targets.size(0)  # Count total samples processed\n",
        "            correct += predicted.eq(targets).sum().item()  # Count correct predictions\n",
        "\n",
        "    # Print validation statistics: Batch index, total loss, and accuracy\n",
        "    print(batch_idx, len(testloader),\n",
        "          'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "          % (test_loss / (batch_idx + 1),  # Average loss per batch\n",
        "             100. * correct / total,  # Compute accuracy percentage\n",
        "             correct, total))  # Display correct/total samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "Tu26LpbukIHQ",
        "outputId": "f8e1dcd9-e24c-45cb-8785-a1bae98b5d5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch  0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-51bdfeec29ab>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_epoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrain_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg16_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mvalidate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg16_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvgg_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-4778a99c5f3a>\u001b[0m in \u001b[0;36mtrain_batch\u001b[0;34m(epoch, model, optimizer)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Set the starting epoch (0 if starting from scratch)\n",
        "start_epoch = 0\n",
        "\n",
        "# Train and validate the model for 3 epochs\n",
        "for epoch in range(start_epoch, start_epoch + 3):\n",
        "\n",
        "    # Train the model for one epoch using the training dataset\n",
        "    train_batch(epoch, vgg16_model, vgg_optimizer)\n",
        "\n",
        "    # Validate the model on the test dataset after each training epoch\n",
        "    validate_batch(epoch, vgg16_model)\n",
        "\n",
        "    # Adjust the learning rate based on the Cosine Annealing schedule\n",
        "    vgg_scheduler.step()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mj9xDQZmkTXe"
      },
      "outputs": [],
      "source": [
        "# Define the path to save the trained model\n",
        "model_path = assets_dir + 'vgg16_model.pt'\n",
        "\n",
        "# Save the model's state dictionary (weights and biases) to the specified path\n",
        "torch.save(vgg16_model.state_dict(), model_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate VGG16"
      ],
      "metadata": {
        "id": "20Cr7s_Usbi2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path where the trained VGG16 model is saved\n",
        "model_path = assets_dir + 'vgg16_model.pt'\n",
        "print(model_path)  # Print the model path for verification\n",
        "\n",
        "# NOTE: Make sure the VGG16 class definition has been run before loading the model\n",
        "# If starting from this cell, ensure that the model architecture is defined\n",
        "\n",
        "# Load the saved state dictionary (model weights)\n",
        "saved_state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "# - `map_location=torch.device('cpu')` ensures compatibility if loading on a CPU system\n",
        "\n",
        "# Load the state dictionary into the VGG16 model\n",
        "vgg16_model.load_state_dict(saved_state_dict)\n",
        "\n",
        "# Set the device: Use GPU if available, otherwise default to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the selected device\n",
        "vgg16_model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode (disables dropout, batch normalization updates)\n",
        "vgg16_model.eval()\n"
      ],
      "metadata": {
        "id": "lMQe0516oPvo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ed22ba8-b4b6-462c-f346-5303e358f611"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IK/CV1/assets/Assignment/vgg16_model.pt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG16(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): ReLU(inplace=True)\n",
              "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (23): ReLU(inplace=True)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=8192, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIe8haQCjyVl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "ca0e06fc-9c7b-4923-b71a-4e6f31f96c51"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-77-37125a247873>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalidate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg16_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-65-aabe7cf1c252>\u001b[0m in \u001b[0;36mvalidate_batch\u001b[0;34m(epoch, model)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-da794c9314f3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Validate the model on the test dataset for one epoch (epoch = 1)\n",
        "validate_batch(1, vgg16_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG19"
      ],
      "metadata": {
        "id": "4xBwfAihrqjq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MK3eGPoGQpAg"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class VGG19(nn.Module):\n",
        "    def __init__(self, num_classes=1000):  # Default: 1000 classes (ImageNet)\n",
        "        super(VGG19, self).__init__()\n",
        "\n",
        "        # Feature Extraction (Convolutional Layers + ReLU + MaxPooling)\n",
        "        self.features = nn.Sequential(\n",
        "            # Block 1 (Conv -> Conv -> MaxPool)\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1), nn.BatchNorm2d(64), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Downsampling (224x224 → 112x112)\n",
        "\n",
        "            # Block 2 (Conv -> Conv -> MaxPool)\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1), nn.BatchNorm2d(128), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Downsampling (112x112 → 56x56)\n",
        "\n",
        "            # Block 3 (Conv -> Conv -> Conv -> Conv -> MaxPool)\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1), nn.BatchNorm2d(256), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Downsampling (56x56 → 28x28)\n",
        "\n",
        "            # Block 4 (Conv -> Conv -> Conv -> Conv -> MaxPool)\n",
        "            nn.Conv2d(256, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Downsampling (28x28 → 14x14)\n",
        "\n",
        "            # Block 5 (Conv -> Conv -> Conv -> Conv -> MaxPool)\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 512, kernel_size=3, padding=1), nn.BatchNorm2d(512), nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Downsampling (14x14 → 7x7)\n",
        "        )\n",
        "\n",
        "        # Adaptive Average Pooling Layer (Ensures fixed-size output)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
        "\n",
        "        # Fully Connected Layers (Classifier)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),  # Prevent overfitting\n",
        "            nn.Linear(512 * 7 * 7, 4096), nn.ReLU(inplace=True), nn.Dropout(0.5),  # First FC layer\n",
        "            nn.Linear(4096, 4096), nn.ReLU(inplace=True), nn.Dropout(0.5),  # Second FC layer\n",
        "            nn.Linear(4096, num_classes)  # Output layer\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the VGG19 model.\n",
        "\n",
        "        Args:\n",
        "        - x (Tensor): Input image batch of shape (batch_size, 3, 224, 224)\n",
        "\n",
        "        Returns:\n",
        "        - Tensor: Output logits of shape (batch_size, num_classes)\n",
        "        \"\"\"\n",
        "        x = self.features(x)  # Pass input through convolutional layers\n",
        "        x = self.avgpool(x)  # Apply adaptive average pooling\n",
        "        x = x.view(x.size(0), -1)  # Flatten feature maps into a 1D vector\n",
        "        x = self.classifier(x)  # Pass through fully connected layers\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9kztYNKjR412",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "062b0d51-9cce-4f90-d6bc-bc64c3fe4503"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VGG19(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (12): ReLU(inplace=True)\n",
            "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (16): ReLU(inplace=True)\n",
            "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (19): ReLU(inplace=True)\n",
            "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (22): ReLU(inplace=True)\n",
            "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (25): ReLU(inplace=True)\n",
            "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (29): ReLU(inplace=True)\n",
            "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (32): ReLU(inplace=True)\n",
            "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (35): ReLU(inplace=True)\n",
            "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (38): ReLU(inplace=True)\n",
            "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (42): ReLU(inplace=True)\n",
            "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (45): ReLU(inplace=True)\n",
            "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (48): ReLU(inplace=True)\n",
            "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (51): ReLU(inplace=True)\n",
            "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "  (classifier): Sequential(\n",
            "    (0): Dropout(p=0.5, inplace=False)\n",
            "    (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): Dropout(p=0.5, inplace=False)\n",
            "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): Dropout(p=0.5, inplace=False)\n",
            "    (7): Linear(in_features=4096, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the VGG19 model with 10 output classes (for CIFAR-10 or similar datasets)\n",
        "vgg19_model = VGG19(num_classes=10)\n",
        "\n",
        "# Print the architecture of the VGG19 model\n",
        "print(vgg19_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dtUbmwkR7kS"
      },
      "outputs": [],
      "source": [
        "# input_tensor = torch.rand(1, 3, 224, 224)\n",
        "# # Get intermediate layer outputs\n",
        "# x, layer_outputs = vgg19_model(input_tensor)\n",
        "\n",
        "# # Print layer outputs\n",
        "# for i, output in enumerate(layer_outputs):\n",
        "#     print(f\"Output after layer {i + 1}: {output.shape}\")\n",
        "\n",
        "# print(\"Final layer output: \", x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlWd_q-GR1sC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c44f1d9-c63b-468c-958a-b7f99933f1f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Parameters: 139622218\n"
          ]
        }
      ],
      "source": [
        "# Calculate the total number of parameters in the VGG19 model\n",
        "total_params = sum(p.numel() for p in vgg19_model.parameters())\n",
        "\n",
        "# Print the total number of parameters in the model\n",
        "print(f\"Total Parameters: {total_params}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozqdgwZ1-AHz"
      },
      "source": [
        "### Training VGG19\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "es8Hgh7F9zRr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr2Q7gTPMyO8"
      },
      "source": [
        "#### Learning Rate\n",
        "\n",
        "The learning rate is a hyperparameter that controls how much the model's parameters should be updated during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9gSqvmp9xog"
      },
      "outputs": [],
      "source": [
        "# Fix the learning rate\n",
        "lr = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBP3MLUy9xlu"
      },
      "outputs": [],
      "source": [
        "# Instantiate the device - 'cuda' or 'cpu'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wGa5Lg3M1yf"
      },
      "source": [
        "#### Loss Function\n",
        "\n",
        "Loss functions measure the difference between the predicted output and the actual target values. Common loss functions include Cross-Entropy Loss for classification tasks and Mean Squared Error for regression tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "do91u6HE9xbC"
      },
      "outputs": [],
      "source": [
        "# Define the criterion\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfWGTqanM4e7"
      },
      "source": [
        "#### Optimizer\n",
        "\n",
        "Optimizers are algorithms that adjust the model's parameters during training to minimize the loss function. Common optimizers include SGD (Stochastic Gradient Descent), Adam, and RMSprop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znXvc0k7idD-"
      },
      "outputs": [],
      "source": [
        "# Define the optimizer\n",
        "vgg19_optimizer = optim.SGD(vgg19_model.parameters(), lr = lr, momentum=0.9, weight_decay = 5e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FellmboeM7GC"
      },
      "source": [
        "#### Scheduler\n",
        "\n",
        "A scheduler adjusts the learning rate dynamically during training, allowing fine-tuning.\n",
        "\n",
        "Cosine Annealing: The learning rate starts high and is annealed down to a minimum value following a cosine curve. It helps the model explore the search space broadly at the beginning of training and then refine the search space as it converges.\n",
        "\n",
        "T_max: This parameter defines the total number of iterations it takes to complete one cycle of the cosine function. The learning rate will follow a cosine curve for the first T_max iterations and then restart the cycle.\n",
        "\n",
        "Here's a conceptual explanation:\n",
        "\n",
        "At the start of training, the learning rate is relatively high, allowing the model to explore a larger area of the loss landscape.\n",
        "As training progresses (over the T_max iterations), the learning rate decreases following a cosine curve.\n",
        "When T_max iterations are completed, the learning rate is at its minimum.\n",
        "The scheduler then restarts the cosine curve, and the learning rate starts to increase again, allowing the model to explore broadly for the next cycle.\n",
        "This approach often helps models converge more efficiently by first exploring broadly and then refining their parameters as training progresses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpBZyUkaiesq"
      },
      "outputs": [],
      "source": [
        "#Define the scheduler\n",
        "vgg19_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(vgg19_optimizer, T_max = 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkcCHOKwM-Wr"
      },
      "source": [
        "Set the models in training mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Li1DhBKiiKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df58b17e-f703-4d21-adcf-8ecafd0a2bdc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG19(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU(inplace=True)\n",
              "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (35): ReLU(inplace=True)\n",
              "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (38): ReLU(inplace=True)\n",
              "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU(inplace=True)\n",
              "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (45): ReLU(inplace=True)\n",
              "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (48): ReLU(inplace=True)\n",
              "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (51): ReLU(inplace=True)\n",
              "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Dropout(p=0.5, inplace=False)\n",
              "    (7): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Train the vgg19 model\n",
        "vgg19_model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fYPGFVWZijk6"
      },
      "outputs": [],
      "source": [
        "# Move the VGG19 model to the specified device (CPU or GPU)\n",
        "vgg19_model = vgg19_model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8UuiAozCgYf"
      },
      "outputs": [],
      "source": [
        "def train_batch(epoch, model, optimizer):\n",
        "    \"\"\"\n",
        "    Trains the model for one epoch using the training dataset.\n",
        "\n",
        "    Args:\n",
        "    - epoch (int): The current training epoch number.\n",
        "    - model (nn.Module): The VGG19 model to be trained.\n",
        "    - optimizer (torch.optim): The optimizer used for updating model weights.\n",
        "\n",
        "    Prints:\n",
        "    - Training loss and accuracy for the current epoch.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Epoch\", epoch)  # Print the current epoch number\n",
        "    model.train()  # Set the model to training mode (enables dropout, batch norm updates)\n",
        "\n",
        "    train_loss = 0  # Variable to accumulate total loss\n",
        "    correct = 0  # Counter for correctly classified samples\n",
        "    total = 0  # Counter for total samples processed\n",
        "\n",
        "    # Iterate over the training batches\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "\n",
        "        # Move input data and targets to the same device as the model (CPU/GPU)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Clear previous gradients\n",
        "        outputs = model(inputs)  # Forward pass: Get model predictions\n",
        "\n",
        "        loss = criterion(outputs, targets)  # Compute loss using CrossEntropyLoss\n",
        "        loss.backward()  # Backpropagation: Compute gradients\n",
        "        optimizer.step()  # Update model parameters\n",
        "\n",
        "        train_loss += loss.item()  # Accumulate total loss\n",
        "\n",
        "        _, predicted = outputs.max(1)  # Get predicted class index (argmax over class dimension)\n",
        "        total += targets.size(0)  # Count total samples processed\n",
        "        correct += predicted.eq(targets).sum().item()  # Count correct predictions\n",
        "\n",
        "    # Print training statistics: Batch index, total loss, and accuracy\n",
        "    print(batch_idx, len(trainloader),\n",
        "          'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "          % (train_loss / (batch_idx + 1),  # Average loss per batch\n",
        "             100. * correct / total,  # Compute accuracy percentage\n",
        "             correct, total))  # Display correct/total samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isuMcWSACgYg"
      },
      "outputs": [],
      "source": [
        "def validate_batch(epoch, model):\n",
        "    \"\"\"\n",
        "    Evaluates the model on the test dataset for one epoch.\n",
        "\n",
        "    Args:\n",
        "    - epoch (int): The current epoch number.\n",
        "    - model (nn.Module): The trained model to be evaluated.\n",
        "\n",
        "    Prints:\n",
        "    - Validation loss and accuracy for the current epoch.\n",
        "    \"\"\"\n",
        "\n",
        "    global best_acc  # Variable to store the best validation accuracy\n",
        "    model.eval()  # Set the model to evaluation mode (disables dropout, batch norm updates)\n",
        "\n",
        "    test_loss = 0  # Variable to accumulate total validation loss\n",
        "    correct = 0  # Counter for correctly classified samples\n",
        "    total = 0  # Counter for total samples processed\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation (reduces memory usage, speeds up validation)\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            # Move inputs and targets to the same device as the model (CPU/GPU)\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)  # Forward pass: Get model predictions\n",
        "            loss = criterion(outputs, targets)  # Compute loss using CrossEntropyLoss\n",
        "\n",
        "            test_loss += loss.item()  # Accumulate total loss\n",
        "            _, predicted = outputs.max(1)  # Get predicted class (argmax over class dimension)\n",
        "            total += targets.size(0)  # Count total samples processed\n",
        "            correct += predicted.eq(targets).sum().item()  # Count correct predictions\n",
        "\n",
        "    # Print validation statistics: Batch index, total loss, and accuracy\n",
        "    print(batch_idx, len(testloader),\n",
        "          'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "          % (test_loss / (batch_idx + 1),  # Average loss per batch\n",
        "             100. * correct / total,  # Compute accuracy percentage\n",
        "             correct, total))  # Display correct/total samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYcWO7-1Gbdj"
      },
      "outputs": [],
      "source": [
        "# Set the starting epoch (0 if starting from scratch)\n",
        "start_epoch = 0\n",
        "\n",
        "# Train and validate the VGG19 model for 3 epochs\n",
        "for epoch in range(start_epoch, start_epoch + 3):\n",
        "\n",
        "    # Train the model for one epoch using the training dataset\n",
        "    train_batch(epoch, vgg19_model, vgg19_optimizer)\n",
        "\n",
        "    # Validate the model on the test dataset after each training epoch\n",
        "    validate_batch(epoch, vgg19_model)\n",
        "\n",
        "    # Adjust the learning rate based on the Cosine Annealing schedule\n",
        "    vgg19_scheduler.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wbQFbtOMXP1"
      },
      "source": [
        "#### Save the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0Zy1ssEJBnp"
      },
      "outputs": [],
      "source": [
        "# Define the path to save the trained VGG19 model\n",
        "model_path = assets_dir + 'vgg19_model.pt'\n",
        "\n",
        "# Save the model's state dictionary (weights and biases) to the specified path\n",
        "torch.save(vgg19_model.state_dict(), model_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQLdznhbCgYq"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdy8RDgJLOpp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bU0v6IjeNIi5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c6586de-d4b2-49c8-c448-23163e911599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/IK/CV1/assets/Assignment/vgg19_model.pt\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG19(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU(inplace=True)\n",
              "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (35): ReLU(inplace=True)\n",
              "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (38): ReLU(inplace=True)\n",
              "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU(inplace=True)\n",
              "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (45): ReLU(inplace=True)\n",
              "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (48): ReLU(inplace=True)\n",
              "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (51): ReLU(inplace=True)\n",
              "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Dropout(p=0.5, inplace=False)\n",
              "    (7): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "# Define the path where the trained VGG19 model is saved\n",
        "model_path = assets_dir + 'vgg19_model.pt'\n",
        "print(model_path)  # Print the model path for verification\n",
        "\n",
        "# NOTE: Make sure the VGG19 class definition has been run before loading the model\n",
        "# If starting from this cell, ensure that the model architecture is defined\n",
        "\n",
        "# Load the saved state dictionary (model weights)\n",
        "saved_state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "# - `map_location=torch.device('cpu')` ensures compatibility if loading on a CPU system\n",
        "\n",
        "# Load the state dictionary into the VGG19 model\n",
        "vgg19_model.load_state_dict(saved_state_dict)\n",
        "\n",
        "# Set the device: Use GPU if available, otherwise default to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the selected device\n",
        "vgg19_model = vgg19_model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode (disables dropout, batch normalization updates)\n",
        "vgg19_model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4QzcU4KNclz"
      },
      "source": [
        "The models performance is the same as the trained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0voANbehiq7w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "c9964ace-7231-40af-fc71-0b2b82c7a06f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-db00e2cdeb89>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalidate_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvgg19_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-65-aabe7cf1c252>\u001b[0m in \u001b[0;36mvalidate_batch\u001b[0;34m(epoch, model)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-ee2658aaa386>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Validate the VGG19 model on the test dataset for one epoch (epoch = 1)\n",
        "epoch = 1\n",
        "validate_batch(epoch, vgg19_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMMNsRCBdXyd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "outputId": "8cbd8fb3-3022-49fe-a4c0-fb93fe11ccf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "VGG19.forward() missing 1 required positional argument: 'x'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-70899cfc9677>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Get model's predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvgg19_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: VGG19.forward() missing 1 required positional argument: 'x'"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Mean and standard deviation used for normalization (CIFAR-10 dataset)\n",
        "mean = [0.4914, 0.4822, 0.4465]\n",
        "std = [0.2470, 0.2434, 0.2616]\n",
        "\n",
        "# Evaluate the VGG19 model on random test images and display results\n",
        "for _ in range(10):\n",
        "\n",
        "    # Fetch a random test image and its label from the test loader\n",
        "    data, target = next(iter(testloader))\n",
        "\n",
        "    # Move the image to the appropriate device (CPU/GPU) before inference\n",
        "    output = vgg19_model(data.to(device))  # Forward pass through the model\n",
        "    _, predicted = torch.max(output, 1)  # Get the class index with highest probability\n",
        "\n",
        "    # Select the first image from the batch for visualization\n",
        "    display_img = data[0]\n",
        "\n",
        "    # Unnormalize the image (convert back to original pixel values)\n",
        "    unnormalized_image = display_img.clone()  # Create a copy to avoid modifying the original tensor\n",
        "    for i in range(3):  # Iterate through the 3 channels (RGB)\n",
        "        unnormalized_image[i] = (unnormalized_image[i] * std[i]) + mean[i]\n",
        "\n",
        "    # Convert tensor to NumPy format and reshape for visualization\n",
        "    plt.imshow(np.transpose(unnormalized_image.numpy(), (1, 2, 0)))\n",
        "\n",
        "    # Display the predicted and actual labels\n",
        "    plt.title(f'Predicted: {classes[predicted[0]]}, Actual: {classes[target[0]]}')\n",
        "    plt.axis('off')  # Remove axis labels for a cleaner visualization\n",
        "    plt.show()  # Display the image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kexMppS7bo1M"
      },
      "source": [
        "# Hybrid Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4lDsGZGe05Q"
      },
      "source": [
        "### What is the Hybrid model?\n",
        "It is a combination of VGG-16, VGG-19 and ResNet-18 pretrained models fine-tuned on the CIFAR-10 dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AGd8VaCfe05R"
      },
      "outputs": [],
      "source": [
        "# Import the required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4N78-zvaEFS"
      },
      "outputs": [],
      "source": [
        "# Load a pre-trained VGG19 model (trained on ImageNet)\n",
        "vgg19 = models.vgg19(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models\n",
        "from torchvision.models import VGG19_Weights\n",
        "\n",
        "# Load the pretrained VGG19 model with new API\n",
        "vgg19_weights = VGG19_Weights.DEFAULT\n",
        "vgg19 = models.vgg19(weights=vgg19_weights)\n"
      ],
      "metadata": {
        "id": "hvTmpm3s6stv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wWv04Kb3aH9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55da07d3-a8c6-47f5-a541-34a2fba632f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (1): ReLU(inplace=True)\n",
              "  (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (3): ReLU(inplace=True)\n",
              "  (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (6): ReLU(inplace=True)\n",
              "  (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (8): ReLU(inplace=True)\n",
              "  (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (11): ReLU(inplace=True)\n",
              "  (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (13): ReLU(inplace=True)\n",
              "  (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (15): ReLU(inplace=True)\n",
              "  (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (17): ReLU(inplace=True)\n",
              "  (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (20): ReLU(inplace=True)\n",
              "  (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (22): ReLU(inplace=True)\n",
              "  (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (24): ReLU(inplace=True)\n",
              "  (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (26): ReLU(inplace=True)\n",
              "  (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (29): ReLU(inplace=True)\n",
              "  (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (31): ReLU(inplace=True)\n",
              "  (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (33): ReLU(inplace=True)\n",
              "  (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (35): ReLU(inplace=True)\n",
              "  (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "vgg19.features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugpG51gXJnZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2d510fb-b797-412d-cbc2-3c615699a62e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "# Load a pre-trained ResNet-18 model (trained on ImageNet)\n",
        "resnet18 = models.resnet18(pretrained=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OMzvxULboXy"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import VGG19_Weights, VGG16_Weights, ResNet18_Weights\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "class HybridModel(nn.Module):\n",
        "    def __init__(self, num_classes=10):  # Default output classes set to 10 (e.g., CIFAR-10)\n",
        "        super(HybridModel, self).__init__()\n",
        "\n",
        "        # Load pre-trained VGG19, VGG16, and ResNet18 models\n",
        "        self.vgg19 = models.vgg19(weights=VGG19_Weights.DEFAULT)\n",
        "        self.vgg16 = models.vgg16(weights=VGG16_Weights.DEFAULT)\n",
        "        self.resnet18 = models.resnet18(weights=ResNet18_Weights.DEFAULT)\n",
        "\n",
        "        # Adaptive average pooling to ensure consistent feature sizes\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "\n",
        "        # Fully connected layer to combine extracted features and classify into num_classes\n",
        "        self.fc = nn.Linear(512 * 3, num_classes)\n",
        "        # The final feature representation is a concatenation of outputs from three models\n",
        "        # 512 from VGG16, 512 from VGG19, and 512 from ResNet18 → total = 512 * 3\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the hybrid model.\n",
        "\n",
        "        Args:\n",
        "        - x (Tensor): Input image batch of shape (batch_size, 3, 224, 224)\n",
        "\n",
        "        Returns:\n",
        "        - Tensor: Output logits of shape (batch_size, num_classes)\n",
        "        \"\"\"\n",
        "\n",
        "        # Pass input through VGG16 feature extractor\n",
        "        x1 = self.vgg16.features(x)  # Output: (batch_size, 512, h, w)\n",
        "        x1 = self.avgpool(x1)  # Adaptive pooling to (batch_size, 512, 1, 1)\n",
        "        x1 = torch.flatten(x1, 1)  # Flatten to (batch_size, 512)\n",
        "\n",
        "        # Pass input through VGG19 feature extractor\n",
        "        x2 = self.vgg19.features(x)  # Output: (batch_size, 512, h, w)\n",
        "        x2 = self.avgpool(x2)  # Adaptive pooling to (batch_size, 512, 1, 1)\n",
        "        x2 = torch.flatten(x2, 1)  # Flatten to (batch_size, 512)\n",
        "\n",
        "        # Pass input through ResNet18 feature extractor\n",
        "        x3 = self.resnet18.conv1(x)  # Initial Conv Layer\n",
        "        x3 = self.resnet18.bn1(x3)  # Batch Normalization\n",
        "        x3 = self.resnet18.relu(x3)  # ReLU Activation\n",
        "        x3 = self.resnet18.maxpool(x3)  # MaxPooling\n",
        "\n",
        "        x3 = self.resnet18.layer1(x3)  # First residual block\n",
        "        x3 = self.resnet18.layer2(x3)  # Second residual block\n",
        "        x3 = self.resnet18.layer3(x3)  # Third residual block\n",
        "        x3 = self.resnet18.layer4(x3)  # Fourth residual block (Output: (batch_size, 512, h, w))\n",
        "\n",
        "        x3 = self.avgpool(x3)  # Adaptive pooling to (batch_size, 512, 1, 1)\n",
        "        x3 = torch.flatten(x3, 1)  # Flatten to (batch_size, 512)\n",
        "\n",
        "        # Concatenate extracted features from all three models\n",
        "        x = torch.cat((x1, x2, x3), dim=1)  # Shape: (batch_size, 512 * 3)\n",
        "\n",
        "        # Fully connected layer for classification\n",
        "        x = self.fc(x)  # Output: (batch_size, num_classes)\n",
        "\n",
        "        return x  # Returns final class predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Key Features of HybridModel\n",
        "- Combines Three Powerful Models (VGG16, VGG19, ResNet18) → Leverages their strengths for richer feature extraction.\n",
        "- Uses Pre-trained Weights → Faster convergence, better performance on small datasets.\n",
        "- Adaptive Pooling Ensures Consistency → All extracted feature maps are resized to (1,1), ensuring equal feature dimensions.\n",
        "- Feature Concatenation (512*3 = 1536 Features) → Merges extracted features before classification.\n",
        "- Fully Connected Layer (fc) for Final Classification → Maps the combined features to num_classes.\n",
        "\n",
        "This architecture is ideal for image classification tasks requiring diverse feature extraction!"
      ],
      "metadata": {
        "id": "lfEw39sWP60B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "paO4ynTEe05R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e09d67f5-6376-4f7e-e422-7f5219dfe1c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HybridModel(\n",
            "  (vgg19): VGG(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (6): ReLU(inplace=True)\n",
            "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (8): ReLU(inplace=True)\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (13): ReLU(inplace=True)\n",
            "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (15): ReLU(inplace=True)\n",
            "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (17): ReLU(inplace=True)\n",
            "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (20): ReLU(inplace=True)\n",
            "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (22): ReLU(inplace=True)\n",
            "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (24): ReLU(inplace=True)\n",
            "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (26): ReLU(inplace=True)\n",
            "      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (29): ReLU(inplace=True)\n",
            "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (31): ReLU(inplace=True)\n",
            "      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (33): ReLU(inplace=True)\n",
            "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (35): ReLU(inplace=True)\n",
            "      (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "    (classifier): Sequential(\n",
            "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "      (4): ReLU(inplace=True)\n",
            "      (5): Dropout(p=0.5, inplace=False)\n",
            "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (vgg16): VGG(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (6): ReLU(inplace=True)\n",
            "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (8): ReLU(inplace=True)\n",
            "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (11): ReLU(inplace=True)\n",
            "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (13): ReLU(inplace=True)\n",
            "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (15): ReLU(inplace=True)\n",
            "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (18): ReLU(inplace=True)\n",
            "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (20): ReLU(inplace=True)\n",
            "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (22): ReLU(inplace=True)\n",
            "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (25): ReLU(inplace=True)\n",
            "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (27): ReLU(inplace=True)\n",
            "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (29): ReLU(inplace=True)\n",
            "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
            "    (classifier): Sequential(\n",
            "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Dropout(p=0.5, inplace=False)\n",
            "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
            "      (4): ReLU(inplace=True)\n",
            "      (5): Dropout(p=0.5, inplace=False)\n",
            "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (resnet18): ResNet(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=1536, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the HybridModel with 10 output classes (e.g., for CIFAR-10)\n",
        "hybrid_model = HybridModel(num_classes=10)\n",
        "\n",
        "# Print the architecture of the HybridModel\n",
        "print(hybrid_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZlOnLaRe05S"
      },
      "outputs": [],
      "source": [
        "# input_tensor = torch.rand(1, 3, 224, 224)\n",
        "# # Get intermediate layer outputs\n",
        "# x, layer_outputs = hybrid_model(input_tensor)\n",
        "\n",
        "# # Print layer outputs\n",
        "# for i, output in enumerate(layer_outputs):\n",
        "#     print(f\"Output after layer {i + 1}: {output.shape}\")\n",
        "\n",
        "# print(\"Final layer output: \", x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKbYkF6Ue05S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf32e65c-a8d6-4a49-8483-03a1f4ed7964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Parameters: 293729666\n"
          ]
        }
      ],
      "source": [
        "# Calculate the total number of parameters in the HybridModel\n",
        "total_params = sum(p.numel() for p in hybrid_model.parameters())\n",
        "\n",
        "# Print the total number of parameters in the model\n",
        "print(f\"Total Parameters: {total_params}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize your model architecture"
      ],
      "metadata": {
        "id": "aUJDBbNMci2b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdLNoRStbhRK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8947646-f704-4f0b-8865-dec95ede0821"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n",
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.3.1+cu121)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchviz) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4132 sha256=0742238e5aba3faeeb982de3f68e5e7bc4d940be8750f7e8cc8bef103d305bbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n",
            "Collecting hiddenlayer\n",
            "  Downloading hiddenlayer-0.3-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: hiddenlayer\n",
            "Successfully installed hiddenlayer-0.3\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.16.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.16.1\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.18.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy<2.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.13.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.18.1\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.16.1)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.10/dist-packages (1.4.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from pydot) (3.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade torch torchvision\n",
        "!pip install torchviz\n",
        "!pip install hiddenlayer\n",
        "!pip install onnx\n",
        "!pip install onnxruntime\n",
        "!pip install onnx pydot graphviz\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using torchviz"
      ],
      "metadata": {
        "id": "WbwX_Hrbc0ic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do the required imports\n",
        "from torchviz import make_dot\n",
        "from graphviz import Digraph\n"
      ],
      "metadata": {
        "id": "5OrpTGOZxGWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dummy input tensor appropriate for the input dimensions of your model\n",
        "input_tensor = torch.randn(1, 3, 224, 224)  # Example for an input of size 28x28 with 1 channel\n",
        "\n",
        "# Generate the graph\n",
        "dot = make_dot(hybrid_model(input_tensor), params=dict(hybrid_model.named_parameters()))\n",
        "dot.render(assets_dir + 'Hybrid_model_graph', format='png')  # Saves the graph as a PNG file\n"
      ],
      "metadata": {
        "id": "wh9JnTsvxL_H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8660fea0-4740-46d2-d3e2-dd31f094d715"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/IK/CV1/assets/Assignment/Hybrid_model_graph.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using ONNX"
      ],
      "metadata": {
        "id": "qxvCN1nJcwvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.onnx\n",
        "import torchvision.models as models\n",
        "\n",
        "# Define or load your model\n",
        "model = HybridModel()\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Create a dummy input tensor appropriate for your model input\n",
        "dummy_input = torch.randn(1, 3, 224, 224)\n",
        "\n",
        "# Export the model\n",
        "torch.onnx.export(model, dummy_input, assets_dir + \"Hybrid_model.onnx\", verbose=True)\n"
      ],
      "metadata": {
        "id": "t8RKHLnH1sZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "from onnx.tools.net_drawer import GetPydotGraph, GetOpNodeProducer\n",
        "\n",
        "# Load the ONNX model\n",
        "model = onnx.load(assets_dir + 'Hybrid_model.onnx')\n",
        "\n",
        "# Generate graph\n",
        "pydot_graph = GetPydotGraph(model.graph, name=model.graph.name, rankdir=\"TB\",\n",
        "                            node_producer=GetOpNodeProducer(\"docstring\", color=\"yellow\",\n",
        "                                                            fillcolor=\"yellow\", style=\"filled\"))\n",
        "pydot_graph.write_png(assets_dir + 'Hybrid_model_graph_ONNX.png')\n"
      ],
      "metadata": {
        "id": "Jr55d4fa47lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQQM_8NQe05S"
      },
      "source": [
        "## Training the Hybrid model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C0hhpaOSe05S"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qpRvGrvMe05U"
      },
      "source": [
        "### Learning Rate\n",
        "\n",
        "The learning rate is a hyperparameter that controls how much the model's parameters should be updated during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkiA-_Gwe05U"
      },
      "outputs": [],
      "source": [
        "# Define the learning rate\n",
        "lr = 0.001"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TIjcUFre05U"
      },
      "outputs": [],
      "source": [
        "# Define the device - 'cuda' or 'cpu'\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "POoXLWBme05V"
      },
      "source": [
        "### Loss Function\n",
        "\n",
        "Loss functions measure the difference between the predicted output and the actual target values. Common loss functions include Cross-Entropy Loss for classification tasks and Mean Squared Error for regression tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TKgVdRqVe05V"
      },
      "outputs": [],
      "source": [
        "# Define the criterion\n",
        "criterion = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_13cetze05V"
      },
      "source": [
        "### Optimizer\n",
        "\n",
        "Optimizers are algorithms that adjust the model's parameters during training to minimize the loss function. Common optimizers include SGD (Stochastic Gradient Descent), Adam, and RMSprop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlWlfj2Me05V"
      },
      "outputs": [],
      "source": [
        "# Define the optimizer\n",
        "hybrid_optimizer = optim.SGD(hybrid_model.parameters(), lr = 1e-3, momentum=0.9, weight_decay = 5e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nefMyAV8e05V"
      },
      "source": [
        "### Scheduler\n",
        "\n",
        "A scheduler adjusts the learning rate dynamically during training, allowing fine-tuning.\n",
        "\n",
        "Cosine Annealing: The learning rate starts high and is annealed down to a minimum value following a cosine curve. It helps the model explore the search space broadly at the beginning of training and then refine the search space as it converges.\n",
        "\n",
        "T_max: This parameter defines the total number of iterations it takes to complete one cycle of the cosine function. The learning rate will follow a cosine curve for the first T_max iterations and then restart the cycle.\n",
        "\n",
        "Here's a conceptual explanation:\n",
        "\n",
        "At the start of training, the learning rate is relatively high, allowing the model to explore a larger area of the loss landscape.\n",
        "As training progresses (over the T_max iterations), the learning rate decreases following a cosine curve.\n",
        "When T_max iterations are completed, the learning rate is at its minimum.\n",
        "The scheduler then restarts the cosine curve, and the learning rate starts to increase again, allowing the model to explore broadly for the next cycle.\n",
        "This approach often helps models converge more efficiently by first exploring broadly and then refining their parameters as training progresses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_QVyK6be05V"
      },
      "outputs": [],
      "source": [
        "# Define the scheduler\n",
        "hybrid_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(hybrid_optimizer, T_max = 200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JljI-EQqe05W"
      },
      "source": [
        "Set the models in training mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVItFCY5e05W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5825e13d-2669-43ee-cff6-fb8074f2fc45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HybridModel(\n",
              "  (vgg19): VGG(\n",
              "    (features): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (8): ReLU(inplace=True)\n",
              "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (11): ReLU(inplace=True)\n",
              "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (13): ReLU(inplace=True)\n",
              "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (15): ReLU(inplace=True)\n",
              "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (17): ReLU(inplace=True)\n",
              "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (20): ReLU(inplace=True)\n",
              "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (22): ReLU(inplace=True)\n",
              "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (24): ReLU(inplace=True)\n",
              "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (26): ReLU(inplace=True)\n",
              "      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (29): ReLU(inplace=True)\n",
              "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (31): ReLU(inplace=True)\n",
              "      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (33): ReLU(inplace=True)\n",
              "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (35): ReLU(inplace=True)\n",
              "      (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "    (classifier): Sequential(\n",
              "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.5, inplace=False)\n",
              "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Dropout(p=0.5, inplace=False)\n",
              "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (vgg16): VGG(\n",
              "    (features): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (8): ReLU(inplace=True)\n",
              "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (11): ReLU(inplace=True)\n",
              "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (13): ReLU(inplace=True)\n",
              "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (15): ReLU(inplace=True)\n",
              "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (18): ReLU(inplace=True)\n",
              "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (20): ReLU(inplace=True)\n",
              "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (22): ReLU(inplace=True)\n",
              "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (25): ReLU(inplace=True)\n",
              "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (27): ReLU(inplace=True)\n",
              "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (29): ReLU(inplace=True)\n",
              "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "    (classifier): Sequential(\n",
              "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.5, inplace=False)\n",
              "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Dropout(p=0.5, inplace=False)\n",
              "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (resnet18): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=1536, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# Train the hybrid model\n",
        "hybrid_model.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJ0ekJZDe05W"
      },
      "outputs": [],
      "source": [
        "# Move the HybridModel to the specified device (CPU or GPU)\n",
        "hybrid_model = hybrid_model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE_Cb4L-e05W"
      },
      "outputs": [],
      "source": [
        "def train_batch(epoch, model, optimizer):\n",
        "    \"\"\"\n",
        "    Trains the model for one epoch using the training dataset.\n",
        "\n",
        "    Args:\n",
        "    - epoch (int): The current training epoch number.\n",
        "    - model (nn.Module): The hybrid model to be trained.\n",
        "    - optimizer (torch.optim): The optimizer used for updating model weights.\n",
        "\n",
        "    Prints:\n",
        "    - Training loss and accuracy for the current epoch.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Epoch\", epoch)  # Print the current epoch number\n",
        "    model.train()  # Set the model to training mode (enables dropout, batch norm updates)\n",
        "\n",
        "    train_loss = 0  # Variable to accumulate total loss\n",
        "    correct = 0  # Counter for correctly classified samples\n",
        "    total = 0  # Counter for total samples processed\n",
        "\n",
        "    # Iterate over the training batches\n",
        "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
        "\n",
        "        # Move input data and targets to the same device as the model (CPU/GPU)\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        optimizer.zero_grad()  # Clear previous gradients\n",
        "        outputs = model(inputs)  # Forward pass: Get model predictions\n",
        "\n",
        "        loss = criterion(outputs, targets)  # Compute loss using CrossEntropyLoss\n",
        "        loss.backward()  # Backpropagation: Compute gradients\n",
        "        optimizer.step()  # Update model parameters\n",
        "\n",
        "        train_loss += loss.item()  # Accumulate total loss\n",
        "\n",
        "        _, predicted = outputs.max(1)  # Get predicted class index (argmax over class dimension)\n",
        "        total += targets.size(0)  # Count total samples processed\n",
        "        correct += predicted.eq(targets).sum().item()  # Count correct predictions\n",
        "\n",
        "    # Print training statistics: Batch index, total loss, and accuracy\n",
        "    print(batch_idx, len(trainloader),\n",
        "          'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "          % (train_loss / (batch_idx + 1),  # Average loss per batch\n",
        "             100. * correct / total,  # Compute accuracy percentage\n",
        "             correct, total))  # Display correct/total samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wONrTrcMe05W"
      },
      "outputs": [],
      "source": [
        "def validate_batch(epoch, model):\n",
        "    \"\"\"\n",
        "    Evaluates the model on the test dataset for one epoch.\n",
        "\n",
        "    Args:\n",
        "    - epoch (int): The current epoch number.\n",
        "    - model (nn.Module): The trained hybrid model to be evaluated.\n",
        "\n",
        "    Prints:\n",
        "    - Validation loss and accuracy for the current epoch.\n",
        "    \"\"\"\n",
        "\n",
        "    global best_acc  # Variable to store the best validation accuracy\n",
        "    model.eval()  # Set the model to evaluation mode (disables dropout, batch norm updates)\n",
        "\n",
        "    test_loss = 0  # Variable to accumulate total validation loss\n",
        "    correct = 0  # Counter for correctly classified samples\n",
        "    total = 0  # Counter for total samples processed\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation (reduces memory usage, speeds up validation)\n",
        "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
        "            # Move inputs and targets to the same device as the model (CPU/GPU)\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)  # Forward pass: Get model predictions\n",
        "            loss = criterion(outputs, targets)  # Compute loss using CrossEntropyLoss\n",
        "\n",
        "            test_loss += loss.item()  # Accumulate total loss\n",
        "            _, predicted = outputs.max(1)  # Get predicted class (argmax over class dimension)\n",
        "            total += targets.size(0)  # Count total samples processed\n",
        "            correct += predicted.eq(targets).sum().item()  # Count correct predictions\n",
        "\n",
        "    # Print validation statistics: Batch index, total loss, and accuracy\n",
        "    print(batch_idx, len(testloader),\n",
        "          'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "          % (test_loss / (batch_idx + 1),  # Average loss per batch\n",
        "             100. * correct / total,  # Compute accuracy percentage\n",
        "             correct, total))  # Display correct/total samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YDM81tze05W"
      },
      "outputs": [],
      "source": [
        "# Set the starting epoch (0 if starting from scratch)\n",
        "start_epoch = 0\n",
        "\n",
        "# Train and validate the HybridModel for 3 epochs\n",
        "for epoch in range(start_epoch, start_epoch + 3):\n",
        "\n",
        "    # Train the model for one epoch using the training dataset\n",
        "    train_batch(epoch, hybrid_model, hybrid_optimizer)\n",
        "\n",
        "    # Validate the model on the test dataset after each training epoch\n",
        "    validate_batch(epoch, hybrid_model)\n",
        "\n",
        "    # Adjust the learning rate based on the Cosine Annealing schedule\n",
        "    hybrid_scheduler.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQOrK-n8e05W"
      },
      "source": [
        "### Save the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DP068R4Qe05X"
      },
      "outputs": [],
      "source": [
        "model_path = assets_dir+'hybrid_model.pt'\n",
        "# Save the model's state dictionary to the specified path\n",
        "torch.save(hybrid_model.state_dict(), model_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laD-ZwAKe05X"
      },
      "source": [
        "### Load the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLyrb68he05X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ea90764-5fa0-4ff9-c9cf-d1cec9f4dcbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HybridModel(\n",
              "  (vgg19): VGG(\n",
              "    (features): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (8): ReLU(inplace=True)\n",
              "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (11): ReLU(inplace=True)\n",
              "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (13): ReLU(inplace=True)\n",
              "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (15): ReLU(inplace=True)\n",
              "      (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (17): ReLU(inplace=True)\n",
              "      (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (20): ReLU(inplace=True)\n",
              "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (22): ReLU(inplace=True)\n",
              "      (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (24): ReLU(inplace=True)\n",
              "      (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (26): ReLU(inplace=True)\n",
              "      (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (29): ReLU(inplace=True)\n",
              "      (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (31): ReLU(inplace=True)\n",
              "      (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (33): ReLU(inplace=True)\n",
              "      (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (35): ReLU(inplace=True)\n",
              "      (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "    (classifier): Sequential(\n",
              "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.5, inplace=False)\n",
              "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Dropout(p=0.5, inplace=False)\n",
              "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (vgg16): VGG(\n",
              "    (features): Sequential(\n",
              "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (6): ReLU(inplace=True)\n",
              "      (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (8): ReLU(inplace=True)\n",
              "      (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (11): ReLU(inplace=True)\n",
              "      (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (13): ReLU(inplace=True)\n",
              "      (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (15): ReLU(inplace=True)\n",
              "      (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (18): ReLU(inplace=True)\n",
              "      (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (20): ReLU(inplace=True)\n",
              "      (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (22): ReLU(inplace=True)\n",
              "      (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (25): ReLU(inplace=True)\n",
              "      (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (27): ReLU(inplace=True)\n",
              "      (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (29): ReLU(inplace=True)\n",
              "      (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "    (classifier): Sequential(\n",
              "      (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): Dropout(p=0.5, inplace=False)\n",
              "      (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "      (4): ReLU(inplace=True)\n",
              "      (5): Dropout(p=0.5, inplace=False)\n",
              "      (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (resnet18): ResNet(\n",
              "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer4): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "    (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=1536, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "# Load the model\n",
        "model_path = assets_dir+'hybrid_model.pt'\n",
        "\n",
        "# NOTE: Need to run the cells for HybridModel in case you are starting off with this cell\n",
        "\n",
        "# Load the saved state dictionary\n",
        "saved_state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
        "\n",
        "# Load the state dictionary into the model\n",
        "hybrid_model.load_state_dict(saved_state_dict)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "hybrid_model = hybrid_model.to(device)\n",
        "# Evaluate the model\n",
        "hybrid_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoUuusOLe05X"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7ecG0Uie05X"
      },
      "source": [
        "The models performance is the same as the trained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BKCjTd18e05X"
      },
      "outputs": [],
      "source": [
        "# Validate the HybridModel on the test dataset for one epoch (epoch = 1)\n",
        "epoch = 1\n",
        "validate_batch(epoch, hybrid_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tLda6JjGe05Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9914677a-3420-4bb2-8e9e-472921a1cf44"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGbCAYAAAAr/4yjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqNUlEQVR4nO3de5DcdZn2/6t7+jjnYw6ThEmCSSCEGA1EXJQkGGAJHigV1v0pBhaBRUgIlV3XdXclEWqXetQlQpAFCs2uZtmfgGKpoEAVCEspCAgaApiESSSTkNNkJnPu6e7P84ebz8MwCblvTMSV96vKsuzcufOd77d7ru6Z7stECCEIAABJybf6AAAAfzwIBQBARCgAACJCAQAQEQoAgIhQAABEhAIAICIUAAARoQAAiAiFPzGTJ0/WhRdeGP/3I488okQioUceeeQtO6bXe/0xHglr165VIpHQli1bjujet6MtW7YokUho7dq1R3TvhRdeqMmTJx/RnTjyCIUj6MA3pgP/yeVymj59uq688krt3LnzrT48l/vuu08rV658qw/jT8LnPvc5JRIJ/cVf/MWb3rFhwwatXLmS0MNRRygcBV/60pf0rW99S2vWrNGf/dmf6ZZbbtF73/te9ff3/8GP5bTTTtPAwIBOO+0019+77777tGrVqqN0VG8fIQTdeeedmjx5sn7wgx+op6fnTe3ZsGGDVq1aRSjgqCMUjoKzzz5bn/rUp/SZz3xGa9eu1fLly9Xe3q7vf//7h/w7fX19R+VYksmkcrmckkku9VvhkUce0bZt2/SNb3xDxWJR3/3ud9/qQwLeEN8p/gBOP/10SVJ7e7uk3/1stbq6Wps3b9bixYtVU1OjT37yk5Kkcrms1atX64QTTlAul9PYsWN12WWXad++fSN2hhB03XXXaeLEiaqsrNTChQv1/PPPj/q3D/U7hSeeeEKLFy9WQ0ODqqqqNHv2bH3ta1+Lx3fzzTdL0ogfhx1wpI9RkjZv3qzNmzebzufzzz+v008/Xfl8XhMnTtR1112ncrl80Nmvf/3rOuGEE5TNZtXa2qorrrhCXV1do+ZuvvlmTZ06Vfl8XvPmzdNjjz2mBQsWaMGCBaZjOpR169Zp5syZWrhwoRYtWqR169YddK6jo0MXX3yxWltblc1mNWXKFF1++eUqFApau3atzjvvPEnSwoUL4/U4cE0TicRBf9T3+t/ddHZ26m/+5m904oknqrq6WrW1tTr77LP13HPPHfbrGB4e1osvvqgdO3aYvu57771Xs2bNUi6X06xZs/S9733voHN9fX1asWKFJk2apGw2qxkzZugrX/mKXl/ePDAwoGXLlqm5uVk1NTX68Ic/rI6OjkN+7XjzUm/1AbwdHPhm19TUFG8rFos666yz9L73vU9f+cpXVFlZKUm67LLLtHbtWl100UVatmyZ2tvbtWbNGv3yl7/U448/rnQ6LUn64he/qOuuu06LFy/W4sWL9cwzz+jMM89UoVA47PE8+OCD+uAHP6jx48frqquu0rhx4/TCCy/ohz/8oa666ipddtll2r59ux588EF961vfGvX3j8YxfuADH5Ckw/545NVXX9XChQtVLBb1+c9/XlVVVbrtttuUz+dHza5cuVKrVq3SokWLdPnll+ull17SLbfcol/84hcjjvOWW27RlVdeqfe///26+uqrtWXLFp177rlqaGjQxIkTD3s+D2VoaEj33HOPVqxYIUn6y7/8S1100UV69dVXNW7cuDi3fft2zZs3T11dXbr00kt13HHHqaOjQ3fffbf6+/t12mmnadmyZbrxxhv1hS98Qccff7wkxf+2evnll3XvvffqvPPO05QpU7Rz507deuutmj9/vjZs2KDW1tZD/t2Ojg4df/zxWrJkyWF/Af3AAw/oYx/7mGbOnKl/+Zd/0d69e3XRRReNOpchBH34wx/Www8/rIsvvlhz5szRT37yE/3t3/6tOjo6dMMNN8TZCy+8UN/5znd0wQUX6JRTTtFPf/pTnXPOOa6vH0YBR8w3v/nNICk89NBDYffu3eGVV14J//Vf/xWamppCPp8P27ZtCyGEsGTJkiApfP7znx/x9x977LEgKaxbt27E7T/+8Y9H3L5r166QyWTCOeecE8rlcpz7whe+ECSFJUuWxNsefvjhICk8/PDDIYQQisVimDJlSmhrawv79u0b8e+8dtcVV1wRDnb3OBrHGEIIbW1toa2tbdS/93rLly8PksITTzwRb9u1a1eoq6sLkkJ7e/uIf//MM88MpVIpzq5ZsyZICt/4xjdCCCEMDQ2FpqamcPLJJ4fh4eE4t3bt2iApzJ8//7DHdCh33313kBQ2btwYQghh//79IZfLhRtuuGHE3Kc//emQTCbDL37xi1E7Dpy7u+66a8R1fC1J4Zprrhl1e1tb24jzPDg4OOJchBBCe3t7yGaz4Utf+tKI2ySFb37zm6Nue/11O5g5c+aE8ePHh66urnjbAw88ECSNuMb33ntvkBSuu+66EX//4x//eEgkEmHTpk0hhBCefvrpICksX758xNyFF154yK8dbx4/PjoKFi1apJaWFk2aNEmf+MQnVF1dre9973uaMGHCiLnLL798xP++6667VFdXpzPOOEN79uyJ/5k7d66qq6v18MMPS5IeeughFQoFLV26dMSPdZYvX37YY/vlL3+p9vZ2LV++XPX19SP+7LW7DuVoHeOWLVtMv0S97777dMopp2jevHnxtpaWlvjjtwMO/PvLly8f8fuUSy65RLW1tfrRj34kSXrqqae0d+9eXXLJJUql/t8L509+8pNqaGg47PG8kXXr1umkk07SO97xDklSTU2NzjnnnBE/QiqXy7r33nv1oQ99SCeddNKoHZZrYpXNZuO5KJVK2rt3r6qrqzVjxgw988wzb/h3J0+erBDCYV8l7NixQ88++6yWLFmiurq6ePsZZ5yhmTNnjpi97777VFFRoWXLlo24fcWKFQoh6P7775ck/fjHP5Ykffaznx0xt3Tp0jc8Frw5/PjoKLj55ps1ffp0pVIpjR07VjNmzBj1i95UKjXq5fTGjRvV3d2tMWPGHHTvrl27JElbt26VJE2bNm3En7e0tBz2G9mBH2XNmjXL/gX9gY/xjWzdulXvec97Rt0+Y8aMUXMHuz2TyWjq1Knxzw/894Fv3AekUqnf6z31XV1duu+++3TllVdq06ZN8fZTTz1V99xzj37zm99o+vTp2r17t/bv3/+mr4dHuVzW1772NX39619Xe3u7SqVS/LPX/mjz93Go6y5pVPhs3bpVra2tqqmpGTF34Mdir71GyWRSU6ZMGTH3+muGI4NQOArmzZt30Gd9r/XaZ20HlMtljRkz5pC/jGxpaTlix/hm/W84xj8Gd911l4aGhvTVr35VX/3qV0f9+bp16476W35f+01fkv75n/9Z//RP/6S/+qu/0rXXXqvGxkYlk0ktX778kL+ox9sPofBH5Nhjj9VDDz2kU0899aC/OD2gra1N0u+etU+dOjXevnv37lHvADrYvyFJ69ev16JFiw45d6gfW/whjvGNtLW1aePGjaNuf+mllw7677/00ksj/v1CoaD29vb4tR+Y27RpkxYuXBjnisWitmzZotmzZ7+p41y3bp1mzZqla665ZtSf3XrrrfrP//xPrVq1Si0tLaqtrdX69evfcN8b/RipoaFh1DuqCoXCqHcK3X333Vq4cKHuuOOOEbd3dXWpubn5MF+RzWuv++sd7Bo99NBD6unpGfFq4cUXXxyxq62tTeVyWe3t7SNegbz2FRiOHH6n8Efk/PPPV6lU0rXXXjvqz4rFYnzgL1q0SOl0WjfddNOIt+6tXr36sP/Gu9/9bk2ZMkWrV68e9Y3ktbuqqqokadTM0TpG61tSFy9erJ///Od68skn4227d+8e9cpl0aJFymQyuvHGG0f8+3fccYe6u7vjO1dOOukkNTU16fbbb1exWIxz69ate9Ph9corr+jRRx/V+eefr49//OOj/nPRRRdp06ZNeuKJJ5RMJnXuuefqBz/4gZ566qlRuw4c+6Guh/S7oH700UdH3HbbbbeNeqVQUVEx6q2ed911lzo6Og77NVnfkjp+/HjNmTNH//7v/67u7u54+4MPPqgNGzaMmF28eLFKpZLWrFkz4vYbbrhBiURCZ599tiTprLPOkvS7txe/1k033XTY48ab8Nb9jvtPz4F3Hx3sXSSvtWTJklBVVXXQP7vsssuCpHD22WeHG264IaxZsyZcddVVobW1Ndx1111x7u///u+DpLB48eKwZs2acPHFF4fW1tbQ3Nz8hu8+CuF37xRKp9Ohra0trFy5Mtx6663h6quvDmeeeWac+c53vhMkhQsuuCB8+9vfDnfeeedRO8YQ7O8+2r59e2hqagoNDQ1h5cqV4ctf/nKYNm1amD179oh3H4UQwjXXXBMkhTPPPDOsWbMmLF26NFRUVISTTz45FAqFOHfTTTcFSeH9739/uOmmm8KKFStCU1NTOPbYY8OCBQtG/Pvz588/6LuyXuv6668PksKzzz570D/ft29fSKVSYenSpSGEELZt2xbGjRsXKisrw/Lly8Ott94aVq5cGU444YT4DrEdO3aEioqKcMopp4S1a9eGO++8M+zcuTOEEMK//du/BUnhox/9aLjlllvCX//1X4cpU6aMOs9f/OIXg6Rw4YUXhttuuy0sXbo0NDY2hqlTp454l9Xv++6j+++/PySTyTBr1qzwr//6r+Ef//EfQ11dXTjhhBNGXONSqRQWLlwYEolEuPTSS8PNN98cPvKRjxz0nUYf+9jH4v3x5ptvDueff36YM2dOkBRWrlx52GOCHaFwBB2JUAghhNtuuy3MnTs35PP5UFNTE0488cTwuc99Lmzfvj3OlEqlsGrVqjB+/PiQz+fDggULwvr160e9DfFgoRBCCP/93/8dzjjjjFBTUxOqqqrC7Nmzw0033RT/vFgshqVLl4aWlpaQSCRGfSM8kscYgj0UQgjhV7/6VZg/f37I5XJhwoQJ4dprrw133HHHqFAI4XdvQT3uuONCOp0OY8eODZdffvmot+KGEMKNN94Y2traQjabDfPmzQuPP/54mDt3bvjzP//zEXNz584N48aNe8PjO/HEE8MxxxzzhjMLFiwIY8aMiW+D3bp1a/j0pz8dWlpaQjabDVOnTg1XXHFFGBoain/n9ttvD1OnTg0VFRUjrmmpVAp/93d/F5qbm0NlZWU466yzwqZNmw76ltQVK1bE63HqqaeGn/3sZ2H+/PlHNBRCCOGee+4Jxx9/fMhms2HmzJnhu9/9bliyZMmoa9zT0xOuvvrq0NraGtLpdJg2bVr48pe/POJtzCGE0NfXF6644orQ2NgYqqurw7nnnhteeumlIClcf/31pmOCTSKE172eBKByuayWlhZ99KMf1e233y5J6unpUWNjo1avXq0rrrjiLT5CPPvss3rXu96lb3/726Pekow3j98p4G1vcHBw1M/a/+M//kOdnZ0jai4effRRTZgwQZdccskf+AgxMDAw6rbVq1crmUy6yx7xxnilgLe9Rx55RFdffbXOO+88NTU16ZlnntEdd9yh448/Xk8//bQymcxbfYhve6tWrdLTTz+thQsXKpVK6f7779f999+vSy+9VLfeeutbfXh/UggFvO1t2bJFy5Yt05NPPqnOzk41NjZq8eLFuv766w/5IT38YT344INatWqVNmzYoN7eXh1zzDG64IIL9A//8A8jPomO3x+hAACI+J0CACAiFAAAkfmHce88abJr8VB/6fBD/6O3Z9C1O5u3N0dms75fEmaqK8yz44/xZWpDU83hh/5HX69rtbb91ncOW1vGm2c7Xjn8J15fq7Pn8P+fDgckE76fXqYq7de+6OzzqcnXuubrMvb7Sr3jfEvSs+sP/n9GdDCZou9+6HlIJJw/rh8cY7/jJoZ9x13e67ueA92HnzkgWfK10abHDdt3NxYPP/QaZcdz9VTafh+UpI0/2H/YGV4pAAAiQgEAEBEKAICIUAAARIQCACAiFAAAEaEAAIgIBQBARCgAACJCAQAQEQoAgMjcbNLUXO1avKujxz7sbO8eLto7UCqS9h4eSUqV7WUvtXWNrt2V+Urz7Jhxza7dL/za3pUjSTtLe82zhYKvu8VxeZQIvuclRUcn1NCgvZ9GkoZS+1zz1a0N5tmN7S+5dqvSfhKT/b7V5aT9eqZTvu6wbCltnh3YY+9Hk6S+3c7vE0P22VLJdx/P5uxdSdU1vn6iWse3lWpfXZcJrxQAABGhAACICAUAQEQoAAAiQgEAEBEKAICIUAAARIQCACAiFAAAEaEAAIjMnQ71zfaPr0tSKOTMs8mE72PgfYP2z/VXVPg+Sp/N2esFenscn6OX1Nxg/0x6U4u9EkOSBgu+Sodtv91lnq2t9V17R8uF0knf7mTC/jymVPBVnORzVa75urp682whv9+1u5S132+TW3z1D+WEfd77rHFo0F4XMdjnrCEZ9lVRZOrsR1/b4DuHTZPs37NqWnxnsXFM1j7bZK/bsOKVAgAgIhQAABGhAACICAUAQEQoAAAiQgEAEBEKAICIUAAARIQCACAiFAAAEaEAAIjM3UdDzm6dKkfvyPiWKa7dz72wyTxbkfD1E41ttXfx1Df4Opv2dXWZZ6v66l27U1nzpZQkDfXaG4rKRU+bkaRgPy8FDbpWpxzPY1JVvj6bdMp3DmvrGsyzO3a0u3Zn0/ZzHlK+53ZpR89Psdt3DqvG2zubJr/L19tT6Mu45vOV9v1FX0WaUln79dm329fZtKPdvnuwy3d9LHilAACICAUAQEQoAAAiQgEAEBEKAICIUAAARIQCACAiFAAAEaEAAIgIBQBAZP5c/95O3+fAu/YOmGdPPs5Xo1DbUG2e3bfHV3PR22v/aHwi5dtdKtt3P//DF127Vfadw5ome6VDsuT7Oisr7TUX1RN9VSEKjvqHUt61enCnr3Jjy3Z73YoGfFUHVXn79enN+47bU4tRyvqufT5jvz6plK+2IlNjr6CRpKyjimLr5oJrd1+P/bx0bffVp7S02e8rubyvKsSCVwoAgIhQAABEhAIAICIUAAARoQAAiAgFAEBEKAAAIkIBABARCgCAiFAAAESEAgAgMpdytB7j6ynp6bP3jvxq629cu1NJ+7Fkq1yrtb/X3tmUzPkyNZPPmWe3v9rr2t1UV+M7lqy9yyox5OucydXb+4yStcG1e9w4e49MKPr6oF5Vt2s+WbJf/3Sfr/+m0Gvvv0mkfP03+3fbd1c1+7qP0kn7/Wrby8Ou3amk735YUWE/lt59vt2DvY77eNl37avq7Pfbku8ubsIrBQBARCgAACJCAQAQEQoAgIhQAABEhAIAICIUAAARoQAAiAgFAEBEKAAAIvPnrydPHu9a3Nu9wzzbmel07e7faP/4em21/ePokjRUslcAlO2jkqTC0KB5dtKxvuPev8dezyFJPTvt57Ch2ldx0lDjeK6Rtx+HJBV67J/r39nhOyet43xVB13b7BUQvb2+519D5YJ5Npfx3VdS9rYV1fke9qqptR9LT5ev4qR/yFeLEYL9vhLkO5ZCwb67fpLvPj5hStY827nTV0NiwSsFAEBEKAAAIkIBABARCgCAiFAAAESEAgAgIhQAABGhAACICAUAQEQoAAAiQgEAEJm7j1SRdy2uqrV3ibR32nteJKlcZe+o6e32dZoUy/bulmzS1zlz7AnV5tnJM+yXRpKe/aWvP6rg6NZRva+7pbdoP+epTt/uXXvsnTOZXMK1u1TyPUca6LXvL5d9x5Kuss8PF+3nRJKUccz7Dlslx+UsDvuWD/R5j8Xx2B/23Q+Hh+2P/Zpm3/cgBfv9sFA48s/reaUAAIgIBQBARCgAACJCAQAQEQoAgIhQAABEhAIAICIUAAARoQAAiAgFAEBk7lL4+S9+7Vo8vanNPPue5mNcu5/JPGGerc/7Pkq/a9uwefadpzW6dp/8vsnm2d9u3+/a/cKm3a75TK/9o/f9BV8FQKLLPjthsr2yRJLUYq9oqKmrdK3e/rKz5qKnyzxbmbZXnEhScNxtC0X7fVaSSmX7tc9lfXUrfT32+0o5FF27kwnfsQz1209icdC1WkrZz2EY9lUEyXFaujt959CCVwoAgIhQAABEhAIAICIUAAARoQAAiAgFAEBEKAAAIkIBABARCgCAiFAAAESEAgAgMpeJNFRPdi2e1Nhqnp08psW1O1Xaap7ds2mva3e+OmOenb94umt3x/Zu8+xjj6137e7u8nWgJCoc/Tc533OHQqFgnx2uc+2ePPED5tlzzrjAtbs86Ps6v/udtebZnZvtfV2S1F9h774qZ+3XUpJyKXvfVHHY16vUtcc+m85WuHaXi76vszhg70pKVPi+zoZWewfXxGmu1apI2zubqup8fVAWvFIAAESEAgAgIhQAABGhAACICAUAQEQoAAAiQgEAEBEKAICIUAAARIQCACAiFAAAkbk4411zj3Etzu7oMs8WOytdu/fvsM/u67H38EhSS12VefaFzb917f71MzvNs93dJdfuRMLexSJJ+by9X6VUzrt2n3bq/2eenfvu+a7d41ummGeba+pdu7M5e++VJE36m/9jnr33/1/t2v2Tx75pni0O+659Q6u95ycRfP1Eg/32Dq7KOt9z0nTW95jI1diPvbLW16tU6ajsKgdfL1lfj/2xGYaP/PN6XikAACJCAQAQEQoAgIhQAABEhAIAICIUAAARoQAAiAgFAEBEKAAAIkIBABCZay5OmPkJ1+Kewq/Ns13rt7t2D75qz7KqVtdqde4aNM/+9KGtrt2ej7sPDfg+dl9K2D8aL0mZnL26YvGpS127P3H+MvNsQ329a3fCcQ4fe+hu1+6msb4ql7YZs82zn7nyi67dW3fbu1wef/x7rt0TJ9trZbo6fffDYtE+399rr9uQpJSvcUMVeXstxnDCV6FRWZs2z2YyWdfuPdvs34NKBedJMeCVAgAgIhQAABGhAACICAUAQEQoAAAiQgEAEBEKAICIUAAARIQCACAiFAAAEaEAAIjM3Uf7++x9HJK0rXe/eban91XX7spkxjybmVDt2r2z396tUyrYZyUpJM2nW+Wir4tFKV++f+SsFebZ8z50pWt32fFco6enz7U7nbJ3PIVUwbW7pqbBNd+1e695drjoO5ZPfeKz5tnicLdr977+J+2znb7jDrJfn2Tad5+trvP1MA322R+fVVX2x6YkjW21z+crfb1kzePsvUqFWt9xW/BKAQAQEQoAgIhQAABEhAIAICIUAAARoQAAiAgFAEBEKAAAIkIBABARCgCAyPwZ6eKA76PaO/s6zbM/evQB1+7T50w2z45tyrl279lor/MIQ76PmHcVHJUOFa7Vaqmf6po/bd5HzbP79/e6docwbJ7NpLOu3V2D9mMpFn21FR0dL7vmqyrt+xOOahZJamloMc9edtHnXLtv+fYy82zv0GbX7mLBXkXR0OJ7/BSHy675RML+2H/HTN/3t2Om1Jpn+7t9x12RtZ/D42bXuXZb8EoBABARCgCAiFAAAESEAgAgIhQAABGhAACICAUAQEQoAAAiQgEAEBEKAICIUAAARObykW/ccp1r8d5du8yz++ToBJK0f789y1oGfSVCRdl7e/qLzoKilL1fJZ0ruVZPP3aua74qV2me7RvY79rd17vPPJso+3phBgfs95W+/Xtdu/v3+Z4jDdYMmWfTlVWu3ZXDefNsLuXrVZrSZr+v7C+1u3ang73Lase2HtfuYsF3fZrbiubZae9scu3OpO3Xx3OflaRslb37qK/f3tVmxSsFAEBEKAAAIkIBABARCgCAiFAAAESEAgAgIhQAABGhAACICAUAQEQoAAAic83FxvanfJuH7B8DHzvNt3r9/p3m2eyuRtfuTsfHxktpeyWGJJWS9pqLrONj9JI0Z/Z813xfb7d5tliyf+xekvq77fUFw/29vt199uqK3r27XbsLvsupZ5+yV7nMfPds1+7WiRPNs7m0r0KjsX6MebZU8j1v7O9x3MfzvuOe+A77bkmac0q9ebZUSrt2795vv9/29A+4dje02B/7u1/pd+224JUCACAiFAAAEaEAAIgIBQBARCgAACJCAQAQEQoAgIhQAABEhAIAICIUAAARoQAAiMzdR2Ma7X0pkrS/y973UVtV6drdP2jvJ9r83A7X7ormknm2u7fg2p2oKJtnzzz1U67ds6a+2zX/6s4O82wqk3Pt/umDD5hnd7zyimv3+xacah9OVbt25533w8TO/ebZzt32ziZJami0d3blUuaH8e84uqwqEr7dx86y9xMdN2uCa3fX3iHX/NbN9g6u/gHf7uEB+/PpXKWvOyxRsn8P2rq5z7XbglcKAICIUAAARIQCACAiFAAAEaEAAIgIBQBARCgAACJCAQAQEQoAgIhQAABEhAIAIDIXm7znxJNdizt27DHPjh3v66ipm2SfP75tkmt3ub5ont2xq9+1O5u3d5q0Nc9z7e7t6XLNF4eHzbPd3btduxMJe9fLgrM/6No9cfIU82wu6+tsCo7jlqRZc+x9U7/59a9cu0uO69PXb+9gkqQ9fRvMs41jXatVWWPvShpO2PvRJGnLFnuXkSTt3N5rns3mXav16sv2HrOksz+qOGzvMxroTbt2W/BKAQAQEQoAgIhQAABEhAIAICIUAAARoQAAiAgFAEBEKAAAIkIBABARCgCAyPz564kTJ7gWB2XNs5V5+6wkpVMZ82yusdW1e9z4ZvPszGn245CkoUF7dUEpXe/aXSjbKzQkaWho0Dzb3+mruTjl1PeaZ5ta21y72zduNM8+9KOfuHZPmWav0JCkmTOnmWfHjG1y7R4O9sqN4YFO1+4Tm+3VL80h4dpd6Lbfx5Mv+Wouipu3ueabU/buis5OX2VN5aC9uiKRsFdiSFL3Hvt5KQ34dlvwSgEAEBEKAICIUAAARIQCACAiFAAAEaEAAIgIBQBARCgAACJCAQAQEQoAgIhQAABE5gKPk981x7W4dcJe8+yre7pcuzu77PNPbfqNa3dqU7t5NpOqcO0Owd4L0zr+GNfu4+ad6prf8Yr966yrb3DtztfUmmf37d7u2v3szx43z37/njtduxecfqZrfvJke6/WQH+3a3eN45zX19v7uiRpfOX7zLMTanzHnc3kzLPde+3fIySpduZO13wh2HuB9nX5jqWn396VVCz6+ol6WwpHbbcFrxQAABGhAACICAUAQEQoAAAiQgEAEBEKAICIUAAARIQCACAiFAAAEaEAAIjMNRfPrd/oWlxOBPNsX9+ga7eC+bCVKCdcqyvsq5X2DEv6wPs+ZJ6dOM5eoSBJ25w1CqFkr9yoqW907R50VAC8snG9a7eK+8yjx8+a7lrdXF1yzQ/t32OerW9ucu3u6bRXOnTt81U0dGzdYp51NEVIksol+znMVPiek3Z19brmB4ftdREKvmMZLObNs8Vh3/0qUWGvz0knfbsteKUAAIgIBQBARCgAACJCAQAQEQoAgIhQAABEhAIAICIUAAARoQAAiAgFAEBEKAAAInN5z86uLtfiiqS9cyghe9eHJIVg310u2zuYJClbVW+ePeW9C127p51wsnm2MOjreenvs/fwSFJtQ4PjWAZcu3sGOs2zHS8/59r93JNPmGcri5Wu3Vtf3OCab6y0FwNNf8/7XLsHBu2dNse0+nqypsyZaZ4N8nWHtW/tMM9u3eG7z6bTWdf8wKC9+2i46Ct5yqXtvWfJjO/7W1Wu2jxbV5Vz7bbglQIAICIUAAARoQAAiAgFAEBEKAAAIkIBABARCgCAiFAAAESEAgAgIhQAAJH5s9rvfLe9okGSBvr6zLOFYfvH0SWpXBgyz1ZXZly7p8yYa549ce4C1+7M8LB5tirjq+dI7vDNV+Ty5tnhIfv5lqSBfvu1LxbtdQ6SVJNxVACUGl27G2p8tRjFov1+u3envf5BkhrGTTHPVuZ9x53Pps2z+x2PY0nKZOy7J42td+3esbvLNR967fUSmayviqIub/86s/kq1+4Kx6GkHHUbVrxSAABEhAIAICIUAAARoQAAiAgFAEBEKAAAIkIBABARCgCAiFAAAESEAgAgIhQAAJG5OGPsuIm+xUl73oRQdO3u299tnq2q9vWOTD/unebZcsKXqb3D9g6h4Z4e1+5k0teBknP0sRTKva7doWQ/L5VVta7dx82ebp7t7hh07U7VuMZV3WjvYSqHhGt3OmPvptqxc5drd6i3H3fB0dclSRUp+7UvOc9JdbXvApUddWCdXb7H2+599sdE2Dfg2l2W/cATvlNowisFAEBEKAAAIkIBABARCgCAiFAAAESEAgAgIhQAABGhAACICAUAQEQoAAAiczfCvq49rsXDBXvFQMqZTWPGTDDPjh03ybU7kcyaZ4v9vvqHof4+8+zggK+iIVmRds1XVtWZZ4sFX9VBKmevI6iub3TtTpTs57BiuvM5T8n3daYr7ceer7Gfb0nKV9prSNo3t7t2r39hk3m2bXyTa/e4lgbzbH2NvW5DksY0ZVzzhaL92J9/6WXX7lJlzjxbLjn6NiT19tnv4wMDvgoNC14pAAAiQgEAEBEKAICIUAAARIQCACAiFAAAEaEAAIgIBQBARCgAACJCAQAQEQoAgMjcfVQo+Do2krL3fZSDrxukXCqbZ3u7u327ywnzbDbj6xsKjg6UkPDldcl5DpMV5kuvfFWt71hK9tnebntXjiRVZLvsxzHU79ud93XxJPP15tlspa/7qCJj7/lpaRnr2u15TPQMFFy7tavTPJrN2PuDJKmzY7trvqfXfv0rMvbOM0mqra00z2YqXKtVUz3ePJt0fp8w7TziGwEA/2sRCgCAiFAAAESEAgAgIhQAABGhAACICAUAQEQoAAAiQgEAEBEKAICIUAAAROYCnGzW11Miez2R8lVVrtWDBXunSaZg75CRpGzJ3vMzVHStdnU2VSTt3USSFArDrvnCoK/LyiOVtp/zXE29a3fQZPNstug7J+XguNNKSqXs3Vf5qkbX7mTK3q0zodXXTVXheHD29PW4dg8P9plndzq7jIaGfdcnlB0lXMO+B/OAo1cpl/U9926qrzHPTp7U6tptwSsFAEBEKAAAIkIBABARCgCAiFAAAESEAgAgIhQAABGhAACICAUAQEQoAAAic5dCKCdcizNpe01DYXDQtTsk7MdSMWD/2L0kNY23V27U1I1x7R5yHMtAzz7X7szgkGs+6ajcKJQLrt3ZdIV5tqFxnGt3vtJe6dDT0+nanUr5niOVio4aBdnPiSSpGMyjdS0trtU1tfbKjb6uHa7dYbjXPNvb56taeXXXXtd80fGc11v70tPdbZ7N5XwVQSXH3aq7y36+rXilAACICAUAQEQoAAAiQgEAEBEKAICIUAAARIQCACAiFAAAEaEAAIgIBQBARCgAACJzQVG56OvW6Rm09/zU1dm7WCSpONhvni1nql27U9m8ebYUiq7dAwP2c1jo6XHtzjp7ZDIV9oIV31cpBdl7eyoqfJ1Ambz9ejZX2nusJGl4yH6/kqS+3v324aSvO6zgePzs3rndtTuVsF+fqrzvuIfKafNsfUPGtTtfU+OaT6Sy9llnt1tPj/3aDzj713p67L1KA3vss1a8UgAARIQCACAiFAAAEaEAAIgIBQBARCgAACJCAQAQEQoAgIhQAABEhAIAIDLXXOTTvo+k11TXmmcTjo/dS1LBkWW1ja2u3cPD9vqHfV2+eoHBbvvH3dPDvsqFVMFXRpFrqDfPFgd6Xbv7+jrtwxW+eoFUzl5DMlz23a+GC74ql0zaXtFRkfA9/yoO2mtLisF3DkPC/nUWM/bzLUmZbM48u3fvDtfuYP929T9/wf54SzoqMSQpX2Wv3Mhm7NUfktTSMtY8WyyXXbsteKUAAIgIBQBARCgAACJCAQAQEQoAgIhQAABEhAIAICIUAAARoQAAiAgFAEBEKAAAInOZSMrR8yJJWUdnSray2rV78oyp5tmqnL2DSZIGBu2dQ0ln78i+va+aZ8OgvbdFklocnUCSlKluMM/WVNp7XiSpHOznpbtzt2t3sc/ew1SRt/fwSP4OrlBh7+Lp6/X1R1WU7MeSzVW5dtdUOx5vzs6mIUcHVzrluz79A/Y+KElKyH4OQ9LXH7V3j+N6Fguu3blcpXk2k/OdQwteKQAAIkIBABARCgCAiFAAAESEAgAgIhQAABGhAACICAUAQEQoAAAiQgEAEJk/p18sDbsWJwpD5tmaunGu3Rll7LOptGt315D9uAf67JUYkpRwZHAp6TvuYqWv5iJtb2hQKu2ruWjMvMM8W9c03rV7Z8cm8+ye7r2u3dUNTa75QtFe6TBULLl2Nzc2m2drx/oeP/t3/dY8W+zrdu3uHbZ/nekK33NSVz2HpOFh++NzeNj+uJekqir7sfT1+HYnU/Z6juKwr0LD9O8f8Y0AgP+1CAUAQEQoAAAiQgEAEBEKAICIUAAARIQCACAiFAAAEaEAAIgIBQBARCgAAKJECMFetAEA+JPGKwUAQEQoAAAiQgEAEBEKAICIUAAARIQCACAiFAAAEaEAAIgIBQBA9H8Butt9X7YXZgwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-fa06924d7493>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Get model's predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-49-b5543851ab70>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;31m# layer_outputs.append(x1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvgg19\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 512 * x * y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 512 * 1 * 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Use the loaded trained HybridModel\n",
        "model = hybrid_model\n",
        "\n",
        "# Mean and standard deviation used for normalization (CIFAR-10 dataset)\n",
        "mean = [0.4914, 0.4822, 0.4465]\n",
        "std = [0.2470, 0.2434, 0.2616]\n",
        "\n",
        "# Evaluate the model on random test images and display results\n",
        "for _ in range(10):\n",
        "\n",
        "    # Fetch a random test image and its label from the test loader\n",
        "    data, target = next(iter(testloader))\n",
        "\n",
        "    # Move the image to the appropriate device (CPU/GPU) before inference\n",
        "    output = model(data.to(device))  # Forward pass through the model\n",
        "    _, predicted = torch.max(output, 1)  # Get the class index with highest probability\n",
        "\n",
        "    # Select the first image from the batch for visualization\n",
        "    display_img = data[0]\n",
        "\n",
        "    # Unnormalize the image (convert back to original pixel values)\n",
        "    unnormalized_image = display_img.clone()  # Create a copy to avoid modifying the original tensor\n",
        "    for i in range(3):  # Iterate through the 3 channels (RGB)\n",
        "        unnormalized_image[i] = (unnormalized_image[i] * std[i]) + mean[i]\n",
        "\n",
        "    # Convert tensor to NumPy format and reshape for visualization\n",
        "    plt.imshow(np.transpose(unnormalized_image.numpy(), (1, 2, 0)))\n",
        "\n",
        "    # Display the predicted and actual labels\n",
        "    plt.title(f'Predicted: {classes[predicted[0]]}, Actual: {classes[target[0]]}')\n",
        "    plt.axis('off')  # Remove axis labels for a cleaner visualization\n",
        "    plt.show()  # Display the image\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbS1LlTPkSex"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9qL4CbKktRh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8804a77e-4056-4684-8f75-a20e5c9017ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG16(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): ReLU(inplace=True)\n",
              "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (23): ReLU(inplace=True)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=8192, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "from torchvision.models import vgg16\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the file path where the trained VGG16 model is stored\n",
        "file_path = '/content/drive/MyDrive/IK/CV1/assets/Assignment/vgg16_model.pt'\n",
        "\n",
        "# Instantiate a new VGG16 model with 10 output classes (e.g., for CIFAR-10)\n",
        "loaded_vgg_model = VGG16(num_classes=10)\n",
        "\n",
        "# Load the saved state dictionary (model weights) from the file\n",
        "saved_state_dict = torch.load(file_path, map_location=torch.device('cpu'))\n",
        "\n",
        "# Load the saved weights into the newly created model\n",
        "loaded_vgg_model.load_state_dict(saved_state_dict)\n",
        "\n",
        "# Set the device: Use GPU if available, otherwise default to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the selected device\n",
        "loaded_vgg_model = loaded_vgg_model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode (disables dropout, batch norm updates)\n",
        "loaded_vgg_model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet50\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the file path where the trained VGG19 model is stored\n",
        "file_path = '/content/drive/MyDrive/IK/CV1/assets/Assignment/vgg19_model.pt'\n",
        "\n",
        "# Instantiate a new VGG19 model with 10 output classes (e.g., for CIFAR-10)\n",
        "loaded_vgg19_model = VGG19(num_classes=10)\n",
        "\n",
        "# Load the saved state dictionary (model weights) from the file\n",
        "saved_state_dict = torch.load(file_path, map_location=torch.device('cpu'))\n",
        "\n",
        "# Load the saved weights into the newly created model\n",
        "loaded_vgg19_model.load_state_dict(saved_state_dict)\n",
        "\n",
        "# Set the device: Use GPU if available, otherwise default to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the selected device\n",
        "loaded_vgg19_model = loaded_vgg19_model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode (disables dropout, batch norm updates)\n",
        "loaded_vgg19_model.eval()\n"
      ],
      "metadata": {
        "id": "g5A5zBjG6H6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df563605-6f22-4f20-866b-5cc90a151b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG19(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (24): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (27): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU(inplace=True)\n",
              "    (33): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (34): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (35): ReLU(inplace=True)\n",
              "    (36): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (37): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (38): ReLU(inplace=True)\n",
              "    (39): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU(inplace=True)\n",
              "    (43): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (44): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (45): ReLU(inplace=True)\n",
              "    (46): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (47): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (48): ReLU(inplace=True)\n",
              "    (49): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (50): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (51): ReLU(inplace=True)\n",
              "    (52): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Dropout(p=0.5, inplace=False)\n",
              "    (1): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Dropout(p=0.5, inplace=False)\n",
              "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): Dropout(p=0.5, inplace=False)\n",
              "    (7): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oi4MlKHWkibJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f354bf-a42c-4c3e-d1f2-048c364393c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "from torchvision.models import resnet50\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the file path where the trained ResNet-50 model is stored\n",
        "file_path = '/content/drive/MyDrive/IK/CV1/assets/Assignment/resnet50_model.pt'\n",
        "\n",
        "# Load a pre-trained ResNet-50 model (without pre-trained weights)\n",
        "loaded_resnet_model = resnet50(pretrained=False)\n",
        "\n",
        "# Modify the classifier (fully connected) layer to match the number of classes\n",
        "loaded_resnet_model.fc = nn.Linear(in_features=2048, out_features=len(classes))  # Assuming 10 classes\n",
        "\n",
        "# Load the saved state dictionary (model weights) from the file\n",
        "saved_state_dict = torch.load(file_path, map_location=torch.device('cpu'))\n",
        "\n",
        "# Load the saved weights into the newly created model\n",
        "loaded_resnet_model.load_state_dict(saved_state_dict)\n",
        "\n",
        "# Set the device: Use GPU if available, otherwise default to CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Move the model to the selected device\n",
        "loaded_resnet_model = loaded_resnet_model.to(device)\n",
        "\n",
        "# Set the model to evaluation mode (disables dropout, batch norm updates)\n",
        "loaded_resnet_model.eval()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIKLfktPl3n1"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWfjyzjfaC4t"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "def evaluate(model, data_loader):\n",
        "    \"\"\"\n",
        "    Evaluates the model on a given dataset using accuracy, precision, recall, F1-score, and confusion matrix.\n",
        "\n",
        "    Args:\n",
        "    - model (torch.nn.Module): The trained model to be evaluated.\n",
        "    - data_loader (torch.utils.data.DataLoader): DataLoader for the dataset (e.g., test dataset).\n",
        "\n",
        "    Returns:\n",
        "    - accuracy (float): Accuracy score of the model.\n",
        "    - precision (float): Weighted precision score.\n",
        "    - recall (float): Weighted recall score.\n",
        "    - f1 (float): Weighted F1-score.\n",
        "    - cf_matrix (numpy.ndarray): Confusion matrix.\n",
        "    \"\"\"\n",
        "\n",
        "    model.eval()  # Set the model to evaluation mode (disables dropout, batch norm updates)\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient computation for efficiency\n",
        "        for images, labels in data_loader:\n",
        "            images = images.to(device)  # Move images to the appropriate device (CPU/GPU)\n",
        "            labels = labels.to(device)  # Move labels to the appropriate device\n",
        "\n",
        "            # Forward pass to get predictions\n",
        "            outputs = model(images)\n",
        "            _, predicted_labels = torch.max(outputs, 1)  # Get class with highest probability\n",
        "\n",
        "            # Store predictions and true labels for evaluation\n",
        "            predictions.extend(predicted_labels.cpu().numpy())\n",
        "            true_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate evaluation metrics\n",
        "    accuracy = accuracy_score(y_true=true_labels, y_pred=predictions)  # Accuracy\n",
        "    precision = precision_score(y_true=true_labels, y_pred=predictions, average='weighted')  # Precision\n",
        "    recall = recall_score(y_true=true_labels, y_pred=predictions, average='weighted')  # Recall\n",
        "    f1 = f1_score(y_true=true_labels, y_pred=predictions, average='weighted')  # F1-score\n",
        "    cf_matrix = confusion_matrix(y_true=true_labels, y_pred=predictions)  # Confusion matrix\n",
        "\n",
        "    return accuracy, precision, recall, f1, cf_matrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJd5uxobWhVT"
      },
      "source": [
        "### VGG-16 Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYpUZ_AaaFH7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "outputId": "94aa3eba-9b14-4c45-e6a7-1a196c434642"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-f5bdbd2f2b20>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_precision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_recall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaded_vgg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Print final test set performance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Accuracy: {test_accuracy:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test Precision: {test_precision:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-97-475ad244858c>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_loader)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0;31m# Get the predicted class with the highest probability for each image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-da794c9314f3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1532\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1539\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 460\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    454\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 456\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    457\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Evaluate the loaded VGG16 model on the test dataset\n",
        "test_accuracy, test_precision, test_recall, test_f1, cf_matrix = evaluate(loaded_vgg_model, testloader)\n",
        "\n",
        "# Print final test set performance metrics\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")      # Overall accuracy of the model\n",
        "print(f\"Test Precision: {test_precision:.4f}\")    # Precision (weighted average)\n",
        "print(f\"Test Recall: {test_recall:.4f}\")          # Recall (weighted average)\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")            # F1-score (weighted average)\n",
        "\n",
        "# Print the confusion matrix for detailed class-wise performance\n",
        "print(f\"Test Confusion Matrix:\")\n",
        "print(cf_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### VGG-19 Model Evaluation"
      ],
      "metadata": {
        "id": "mn9eTdja6byj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the loaded VGG19 model on the test dataset\n",
        "test_accuracy, test_precision, test_recall, test_f1, cf_matrix = evaluate(loaded_vgg19_model, testloader)\n",
        "\n",
        "# Print final test set performance metrics\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")      # Overall accuracy of the model\n",
        "print(f\"Test Precision: {test_precision:.4f}\")    # Precision (weighted average)\n",
        "print(f\"Test Recall: {test_recall:.4f}\")          # Recall (weighted average)\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")            # F1-score (weighted average)\n",
        "\n",
        "# Print the confusion matrix for detailed class-wise performance\n",
        "print(f\"Test Confusion Matrix:\")\n",
        "print(cf_matrix)\n"
      ],
      "metadata": {
        "id": "GlMbjWnX6hRB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pLFoy7ITWmSQ"
      },
      "source": [
        "### ResNet-50 Model Evaluation (From the Live Class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRNV0JAzfv7P"
      },
      "outputs": [],
      "source": [
        "# Evaluate the loaded ResNet-50 model on the test dataset\n",
        "test_accuracy, test_precision, test_recall, test_f1, cf_matrix = evaluate(loaded_resnet_model, testloader)\n",
        "\n",
        "# Print final test set performance metrics\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")      # Overall accuracy of the model\n",
        "print(f\"Test Precision: {test_precision:.4f}\")    # Precision (weighted average)\n",
        "print(f\"Test Recall: {test_recall:.4f}\")          # Recall (weighted average)\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")            # F1-score (weighted average)\n",
        "\n",
        "# Print the confusion matrix for detailed class-wise performance\n",
        "print(f\"Test Confusion Matrix:\")\n",
        "print(cf_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHi7bzvRkdxb"
      },
      "source": [
        "### Hybrid Model Evaluation (VGG-16, VGG-19, ResNet-18)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzXa7U8Gkasl"
      },
      "outputs": [],
      "source": [
        "# Evaluate the HybridModel on the test dataset\n",
        "test_accuracy, test_precision, test_recall, test_f1, cf_matrix = evaluate(hybrid_model, testloader)\n",
        "\n",
        "# Print final test set performance metrics\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")      # Overall accuracy of the model\n",
        "print(f\"Test Precision: {test_precision:.4f}\")    # Precision (weighted average)\n",
        "print(f\"Test Recall: {test_recall:.4f}\")          # Recall (weighted average)\n",
        "print(f\"Test F1 Score: {test_f1:.4f}\")            # F1-score (weighted average)\n",
        "\n",
        "# Print the confusion matrix for detailed class-wise performance\n",
        "print(f\"Test Confusion Matrix:\")\n",
        "print(cf_matrix)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Summary\n",
        "1. **Data Preparation**\n",
        "- Loaded the CIFAR-10 dataset and applied data augmentation (random cropping, flipping, normalization) for training.\n",
        "- Created DataLoaders for efficient batch processing.\n",
        "2. **Model Implementations**\n",
        "- Implemented VGG16, VGG19, ResNet-50, and a Hybrid Model (VGG16 + VGG19 + ResNet-50).\n",
        "- Modified the fully connected layers to classify 10 classes.\n",
        "- Moved models to GPU (if available) for faster computation.\n",
        "3. **Training and Validation**\n",
        "- Defined `train_batch()` for forward pass, loss computation, backpropagation, and weight updates.\n",
        "- Defined `validate_batch()` to evaluate model performance on the test set.\n",
        "- Applied learning rate scheduling for better training convergence.\n",
        "4. **Model Saving & Loading**\n",
        "- Saved trained models as .pt files to avoid retraining.\n",
        "- Loaded pre-trained models for evaluation.\n",
        "5. **Evaluation & Performance Metrics**\n",
        "- Implemented evaluate() to compute accuracy, precision, recall, F1-score, and confusion matrix.\n",
        "- Evaluated VGG16, VGG19, ResNet-50, and Hybrid Model on the test dataset.\n",
        "6. **Visualization**\n",
        "- Displayed model predictions on test images.\n",
        "- Extracted and visualized feature maps from convolutional layers."
      ],
      "metadata": {
        "id": "skpCnsB6UDhV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-sqX-Z0k3xT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}